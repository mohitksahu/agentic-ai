{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "509e23fc",
   "metadata": {},
   "source": [
    "# ü§ñ Agentic Financial AI Assistant - RAG System\n",
    "\n",
    "This Financial AI Assistant uses a **Retrieval Augmented Generation (RAG)** approach, meaning it only works with **YOUR actual financial data**. \n",
    "\n",
    "## üìä How It Works:\n",
    "1. **Upload your financial data** (CSV or PDF files)\n",
    "2. **Ask questions** about your finances\n",
    "3. **Get personalized insights** based solely on your uploaded data\n",
    "\n",
    "## üìÅ Supported File Types:\n",
    "- **CSV files**: Transaction data with columns like date, amount, category/description\n",
    "- **PDF files**: Bank statements and financial reports (automatically parsed)\n",
    "\n",
    "## ‚ö†Ô∏è Important:\n",
    "- This system provides **NO analysis without your data**\n",
    "- All insights are generated from **your uploaded files only**\n",
    "- No sample or demo data is used - everything is based on your actual financial information"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57964113",
   "metadata": {},
   "source": [
    "# Agentic Financial AI Chatbot\n",
    "\n",
    "This notebook provides a comprehensive financial analysis and budgeting assistant powered by AI.\n",
    "\n",
    "## Workflow Overview:\n",
    "1. **Initialize Libraries & Models** - Load required dependencies and AI models\n",
    "2. **Data Input** - Upload or select CSV/PDF financial data files\n",
    "3. **Data Processing** - Parse and analyze financial data\n",
    "4. **Visualization** - Generate interactive charts and graphs\n",
    "5. **AI Chat Interface** - Interactive assistant for financial advice and insights\n",
    "\n",
    "> **Models Used**: GPT-2 and DistilBERT (no authentication required)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4c7c6630",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Found project directory: f:\\agentic-ai\n",
      "üìÅ Current working directory: f:\\agentic-ai\n",
      "\n",
      "üìÇ Project structure:\n",
      "   üìÅ .git/\n",
      "   üìÅ agents/\n",
      "   üìÅ analysis/\n",
      "   üìÑ cleanup.py\n",
      "   üìÅ data/\n",
      "   üìÅ llms/\n",
      "   üìÑ main.ipynb\n",
      "   üìÅ models/\n",
      "   üìÅ parsers/\n",
      "   üìÑ README.md\n",
      "   üìÑ requirements.txt\n",
      "   üìÑ test_setup.py\n",
      "   üìÅ utils/\n",
      "   üìÅ venv/\n",
      "   üìÅ visualizations/\n",
      "\n",
      "‚úÖ Ready to proceed with setup!\n"
     ]
    }
   ],
   "source": [
    "# Change to the agentic-ai directory\n",
    "import os\n",
    "import sys\n",
    "\n",
    "# Try to find the agentic-ai directory\n",
    "possible_paths = [\n",
    "    './agentic-ai',\n",
    "    '../agentic-ai', \n",
    "    './financial-agentic-ai',\n",
    "    '../financial-agentic-ai',\n",
    "    '.'  # Current directory if already in project\n",
    "]\n",
    "\n",
    "project_found = False\n",
    "for path in possible_paths:\n",
    "    if os.path.exists(path) and os.path.exists(os.path.join(path, 'agents')):\n",
    "        os.chdir(path)\n",
    "        project_found = True\n",
    "        print(f\"‚úÖ Found project directory: {os.path.abspath(path)}\")\n",
    "        break\n",
    "\n",
    "if not project_found:\n",
    "    print(\"‚ùå Project directory not found. Please ensure you have cloned the repository.\")\n",
    "    print(\"üí° Available directories:\")\n",
    "    for item in os.listdir('.'):\n",
    "        if os.path.isdir(item):\n",
    "            print(f\"   üìÅ {item}\")\n",
    "else:\n",
    "    print(f\"üìÅ Current working directory: {os.getcwd()}\")\n",
    "    \n",
    "    # List project structure\n",
    "    print(f\"\\nüìÇ Project structure:\")\n",
    "    for item in os.listdir('.'):\n",
    "        if os.path.isdir(item):\n",
    "            print(f\"   üìÅ {item}/\")\n",
    "        elif item.endswith(('.py', '.ipynb', '.txt', '.md')):\n",
    "            print(f\"   üìÑ {item}\")\n",
    "            \n",
    "    print(f\"\\n‚úÖ Ready to proceed with setup!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7f5563d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas>=2.0.3 in .\\venv\\lib\\site-packages (from -r requirements.txt (line 2)) (2.3.1)\n",
      "Requirement already satisfied: numpy>=1.24.3 in .\\venv\\lib\\site-packages (from -r requirements.txt (line 3)) (2.3.2)\n",
      "Requirement already satisfied: scipy>=1.11.0 in .\\venv\\lib\\site-packages (from -r requirements.txt (line 4)) (1.16.1)\n",
      "Requirement already satisfied: scikit-learn>=1.3.0 in .\\venv\\lib\\site-packages (from -r requirements.txt (line 7)) (1.7.1)\n",
      "Requirement already satisfied: transformers>=4.31.0 in .\\venv\\lib\\site-packages (from -r requirements.txt (line 8)) (4.55.0)\n",
      "Requirement already satisfied: torch>=2.0.1 in .\\venv\\lib\\site-packages (from -r requirements.txt (line 9)) (2.8.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.16.4 in .\\venv\\lib\\site-packages (from -r requirements.txt (line 10)) (0.34.4)\n",
      "Requirement already satisfied: tokenizers>=0.13.3 in .\\venv\\lib\\site-packages (from -r requirements.txt (line 11)) (0.21.4)\n",
      "Requirement already satisfied: sentence-transformers>=2.2.2 in .\\venv\\lib\\site-packages (from -r requirements.txt (line 12)) (5.1.0)\n",
      "Requirement already satisfied: matplotlib>=3.7.0 in .\\venv\\lib\\site-packages (from -r requirements.txt (line 15)) (3.10.5)\n",
      "Requirement already satisfied: plotly>=5.15.0 in .\\venv\\lib\\site-packages (from -r requirements.txt (line 16)) (6.2.0)\n",
      "Requirement already satisfied: seaborn>=0.12.0 in .\\venv\\lib\\site-packages (from -r requirements.txt (line 17)) (0.13.2)\n",
      "Requirement already satisfied: PyPDF2>=3.0.1 in .\\venv\\lib\\site-packages (from -r requirements.txt (line 20)) (3.0.1)\n",
      "Requirement already satisfied: openpyxl>=3.1.0 in .\\venv\\lib\\site-packages (from -r requirements.txt (line 21)) (3.1.5)\n",
      "Requirement already satisfied: pdfplumber>=0.9.0 in .\\venv\\lib\\site-packages (from -r requirements.txt (line 22)) (0.11.7)\n",
      "Requirement already satisfied: tabula-py>=2.7.0 in .\\venv\\lib\\site-packages (from -r requirements.txt (line 23)) (2.10.0)\n",
      "Requirement already satisfied: jupyter>=1.0.0 in .\\venv\\lib\\site-packages (from -r requirements.txt (line 26)) (1.1.1)\n",
      "Requirement already satisfied: notebook>=7.0.0 in .\\venv\\lib\\site-packages (from -r requirements.txt (line 27)) (7.4.5)\n",
      "Requirement already satisfied: ipywidgets>=8.0.0 in .\\venv\\lib\\site-packages (from -r requirements.txt (line 28)) (8.1.7)\n",
      "Requirement already satisfied: python-dotenv>=1.0.0 in .\\venv\\lib\\site-packages (from -r requirements.txt (line 31)) (1.1.1)\n",
      "Requirement already satisfied: psutil>=5.9.5 in .\\venv\\lib\\site-packages (from -r requirements.txt (line 32)) (7.0.0)\n",
      "Requirement already satisfied: pydantic>=2.1.1 in .\\venv\\lib\\site-packages (from -r requirements.txt (line 33)) (2.11.7)\n",
      "Requirement already satisfied: langchain>=0.0.250 in .\\venv\\lib\\site-packages (from -r requirements.txt (line 36)) (0.3.27)\n",
      "Requirement already satisfied: streamlit>=1.25.0 in .\\venv\\lib\\site-packages (from -r requirements.txt (line 37)) (1.48.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in .\\venv\\lib\\site-packages (from pandas>=2.0.3->-r requirements.txt (line 2)) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in .\\venv\\lib\\site-packages (from pandas>=2.0.3->-r requirements.txt (line 2)) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in .\\venv\\lib\\site-packages (from pandas>=2.0.3->-r requirements.txt (line 2)) (2025.2)\n",
      "Requirement already satisfied: joblib>=1.2.0 in .\\venv\\lib\\site-packages (from scikit-learn>=1.3.0->-r requirements.txt (line 7)) (1.5.1)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in .\\venv\\lib\\site-packages (from scikit-learn>=1.3.0->-r requirements.txt (line 7)) (3.6.0)\n",
      "Requirement already satisfied: filelock in .\\venv\\lib\\site-packages (from transformers>=4.31.0->-r requirements.txt (line 8)) (3.18.0)\n",
      "Requirement already satisfied: packaging>=20.0 in .\\venv\\lib\\site-packages (from transformers>=4.31.0->-r requirements.txt (line 8)) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in .\\venv\\lib\\site-packages (from transformers>=4.31.0->-r requirements.txt (line 8)) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in .\\venv\\lib\\site-packages (from transformers>=4.31.0->-r requirements.txt (line 8)) (2025.7.34)\n",
      "Requirement already satisfied: requests in .\\venv\\lib\\site-packages (from transformers>=4.31.0->-r requirements.txt (line 8)) (2.32.4)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in .\\venv\\lib\\site-packages (from transformers>=4.31.0->-r requirements.txt (line 8)) (0.6.1)\n",
      "Requirement already satisfied: tqdm>=4.27 in .\\venv\\lib\\site-packages (from transformers>=4.31.0->-r requirements.txt (line 8)) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in .\\venv\\lib\\site-packages (from torch>=2.0.1->-r requirements.txt (line 9)) (4.14.1)\n",
      "Requirement already satisfied: sympy>=1.13.3 in .\\venv\\lib\\site-packages (from torch>=2.0.1->-r requirements.txt (line 9)) (1.14.0)\n",
      "Requirement already satisfied: networkx in .\\venv\\lib\\site-packages (from torch>=2.0.1->-r requirements.txt (line 9)) (3.5)\n",
      "Requirement already satisfied: jinja2 in .\\venv\\lib\\site-packages (from torch>=2.0.1->-r requirements.txt (line 9)) (3.1.6)\n",
      "Requirement already satisfied: fsspec in .\\venv\\lib\\site-packages (from torch>=2.0.1->-r requirements.txt (line 9)) (2025.7.0)\n",
      "Requirement already satisfied: Pillow in .\\venv\\lib\\site-packages (from sentence-transformers>=2.2.2->-r requirements.txt (line 12)) (11.3.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in .\\venv\\lib\\site-packages (from matplotlib>=3.7.0->-r requirements.txt (line 15)) (1.3.3)\n",
      "Requirement already satisfied: cycler>=0.10 in .\\venv\\lib\\site-packages (from matplotlib>=3.7.0->-r requirements.txt (line 15)) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in .\\venv\\lib\\site-packages (from matplotlib>=3.7.0->-r requirements.txt (line 15)) (4.59.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in .\\venv\\lib\\site-packages (from matplotlib>=3.7.0->-r requirements.txt (line 15)) (1.4.8)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in .\\venv\\lib\\site-packages (from matplotlib>=3.7.0->-r requirements.txt (line 15)) (3.2.3)\n",
      "Requirement already satisfied: narwhals>=1.15.1 in .\\venv\\lib\\site-packages (from plotly>=5.15.0->-r requirements.txt (line 16)) (2.0.1)\n",
      "Requirement already satisfied: et-xmlfile in .\\venv\\lib\\site-packages (from openpyxl>=3.1.0->-r requirements.txt (line 21)) (2.0.0)\n",
      "Requirement already satisfied: pdfminer.six==20250506 in .\\venv\\lib\\site-packages (from pdfplumber>=0.9.0->-r requirements.txt (line 22)) (20250506)\n",
      "Requirement already satisfied: pypdfium2>=4.18.0 in .\\venv\\lib\\site-packages (from pdfplumber>=0.9.0->-r requirements.txt (line 22)) (4.30.0)\n",
      "Requirement already satisfied: charset-normalizer>=2.0.0 in .\\venv\\lib\\site-packages (from pdfminer.six==20250506->pdfplumber>=0.9.0->-r requirements.txt (line 22)) (3.4.2)\n",
      "Requirement already satisfied: cryptography>=36.0.0 in .\\venv\\lib\\site-packages (from pdfminer.six==20250506->pdfplumber>=0.9.0->-r requirements.txt (line 22)) (45.0.6)\n",
      "Requirement already satisfied: distro in .\\venv\\lib\\site-packages (from tabula-py>=2.7.0->-r requirements.txt (line 23)) (1.9.0)\n",
      "Requirement already satisfied: jupyter-console in .\\venv\\lib\\site-packages (from jupyter>=1.0.0->-r requirements.txt (line 26)) (6.6.3)\n",
      "Requirement already satisfied: nbconvert in .\\venv\\lib\\site-packages (from jupyter>=1.0.0->-r requirements.txt (line 26)) (7.16.6)\n",
      "Requirement already satisfied: ipykernel in .\\venv\\lib\\site-packages (from jupyter>=1.0.0->-r requirements.txt (line 26)) (6.30.1)\n",
      "Requirement already satisfied: jupyterlab in .\\venv\\lib\\site-packages (from jupyter>=1.0.0->-r requirements.txt (line 26)) (4.4.5)\n",
      "Requirement already satisfied: jupyter-server<3,>=2.4.0 in .\\venv\\lib\\site-packages (from notebook>=7.0.0->-r requirements.txt (line 27)) (2.16.0)\n",
      "Requirement already satisfied: jupyterlab-server<3,>=2.27.1 in .\\venv\\lib\\site-packages (from notebook>=7.0.0->-r requirements.txt (line 27)) (2.27.3)\n",
      "Requirement already satisfied: notebook-shim<0.3,>=0.2 in .\\venv\\lib\\site-packages (from notebook>=7.0.0->-r requirements.txt (line 27)) (0.2.4)\n",
      "Requirement already satisfied: tornado>=6.2.0 in .\\venv\\lib\\site-packages (from notebook>=7.0.0->-r requirements.txt (line 27)) (6.5.1)\n",
      "Requirement already satisfied: comm>=0.1.3 in .\\venv\\lib\\site-packages (from ipywidgets>=8.0.0->-r requirements.txt (line 28)) (0.2.3)\n",
      "Requirement already satisfied: ipython>=6.1.0 in .\\venv\\lib\\site-packages (from ipywidgets>=8.0.0->-r requirements.txt (line 28)) (9.4.0)\n",
      "Requirement already satisfied: traitlets>=4.3.1 in .\\venv\\lib\\site-packages (from ipywidgets>=8.0.0->-r requirements.txt (line 28)) (5.14.3)\n",
      "Requirement already satisfied: widgetsnbextension~=4.0.14 in .\\venv\\lib\\site-packages (from ipywidgets>=8.0.0->-r requirements.txt (line 28)) (4.0.14)\n",
      "Requirement already satisfied: jupyterlab_widgets~=3.0.15 in .\\venv\\lib\\site-packages (from ipywidgets>=8.0.0->-r requirements.txt (line 28)) (3.0.15)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in .\\venv\\lib\\site-packages (from pydantic>=2.1.1->-r requirements.txt (line 33)) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in .\\venv\\lib\\site-packages (from pydantic>=2.1.1->-r requirements.txt (line 33)) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in .\\venv\\lib\\site-packages (from pydantic>=2.1.1->-r requirements.txt (line 33)) (0.4.1)\n",
      "Requirement already satisfied: langchain-core<1.0.0,>=0.3.72 in .\\venv\\lib\\site-packages (from langchain>=0.0.250->-r requirements.txt (line 36)) (0.3.73)\n",
      "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.9 in .\\venv\\lib\\site-packages (from langchain>=0.0.250->-r requirements.txt (line 36)) (0.3.9)\n",
      "Requirement already satisfied: langsmith>=0.1.17 in .\\venv\\lib\\site-packages (from langchain>=0.0.250->-r requirements.txt (line 36)) (0.4.13)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in .\\venv\\lib\\site-packages (from langchain>=0.0.250->-r requirements.txt (line 36)) (2.0.42)\n",
      "Requirement already satisfied: altair!=5.4.0,!=5.4.1,<6,>=4.0 in .\\venv\\lib\\site-packages (from streamlit>=1.25.0->-r requirements.txt (line 37)) (5.5.0)\n",
      "Requirement already satisfied: blinker<2,>=1.5.0 in .\\venv\\lib\\site-packages (from streamlit>=1.25.0->-r requirements.txt (line 37)) (1.9.0)\n",
      "Requirement already satisfied: cachetools<7,>=4.0 in .\\venv\\lib\\site-packages (from streamlit>=1.25.0->-r requirements.txt (line 37)) (5.5.2)\n",
      "Requirement already satisfied: click<9,>=7.0 in .\\venv\\lib\\site-packages (from streamlit>=1.25.0->-r requirements.txt (line 37)) (8.2.1)\n",
      "Requirement already satisfied: protobuf<7,>=3.20 in .\\venv\\lib\\site-packages (from streamlit>=1.25.0->-r requirements.txt (line 37)) (6.31.1)\n",
      "Requirement already satisfied: pyarrow>=7.0 in .\\venv\\lib\\site-packages (from streamlit>=1.25.0->-r requirements.txt (line 37)) (21.0.0)\n",
      "Requirement already satisfied: tenacity<10,>=8.1.0 in .\\venv\\lib\\site-packages (from streamlit>=1.25.0->-r requirements.txt (line 37)) (9.1.2)\n",
      "Requirement already satisfied: toml<2,>=0.10.1 in .\\venv\\lib\\site-packages (from streamlit>=1.25.0->-r requirements.txt (line 37)) (0.10.2)\n",
      "Requirement already satisfied: watchdog<7,>=2.1.5 in .\\venv\\lib\\site-packages (from streamlit>=1.25.0->-r requirements.txt (line 37)) (6.0.0)\n",
      "Requirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in .\\venv\\lib\\site-packages (from streamlit>=1.25.0->-r requirements.txt (line 37)) (3.1.45)\n",
      "Requirement already satisfied: pydeck<1,>=0.8.0b4 in .\\venv\\lib\\site-packages (from streamlit>=1.25.0->-r requirements.txt (line 37)) (0.9.1)\n",
      "Requirement already satisfied: jsonschema>=3.0 in .\\venv\\lib\\site-packages (from altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit>=1.25.0->-r requirements.txt (line 37)) (4.25.0)\n",
      "Requirement already satisfied: colorama in .\\venv\\lib\\site-packages (from click<9,>=7.0->streamlit>=1.25.0->-r requirements.txt (line 37)) (0.4.6)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in .\\venv\\lib\\site-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit>=1.25.0->-r requirements.txt (line 37)) (4.0.12)\n",
      "Requirement already satisfied: decorator in .\\venv\\lib\\site-packages (from ipython>=6.1.0->ipywidgets>=8.0.0->-r requirements.txt (line 28)) (5.2.1)\n",
      "Requirement already satisfied: ipython-pygments-lexers in .\\venv\\lib\\site-packages (from ipython>=6.1.0->ipywidgets>=8.0.0->-r requirements.txt (line 28)) (1.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in .\\venv\\lib\\site-packages (from ipython>=6.1.0->ipywidgets>=8.0.0->-r requirements.txt (line 28)) (0.19.2)\n",
      "Requirement already satisfied: matplotlib-inline in .\\venv\\lib\\site-packages (from ipython>=6.1.0->ipywidgets>=8.0.0->-r requirements.txt (line 28)) (0.1.7)\n",
      "Requirement already satisfied: prompt_toolkit<3.1.0,>=3.0.41 in .\\venv\\lib\\site-packages (from ipython>=6.1.0->ipywidgets>=8.0.0->-r requirements.txt (line 28)) (3.0.51)\n",
      "Requirement already satisfied: pygments>=2.4.0 in .\\venv\\lib\\site-packages (from ipython>=6.1.0->ipywidgets>=8.0.0->-r requirements.txt (line 28)) (2.19.2)\n",
      "Requirement already satisfied: stack_data in .\\venv\\lib\\site-packages (from ipython>=6.1.0->ipywidgets>=8.0.0->-r requirements.txt (line 28)) (0.6.3)\n",
      "Requirement already satisfied: anyio>=3.1.0 in .\\venv\\lib\\site-packages (from jupyter-server<3,>=2.4.0->notebook>=7.0.0->-r requirements.txt (line 27)) (4.10.0)\n",
      "Requirement already satisfied: argon2-cffi>=21.1 in .\\venv\\lib\\site-packages (from jupyter-server<3,>=2.4.0->notebook>=7.0.0->-r requirements.txt (line 27)) (25.1.0)\n",
      "Requirement already satisfied: jupyter-client>=7.4.4 in .\\venv\\lib\\site-packages (from jupyter-server<3,>=2.4.0->notebook>=7.0.0->-r requirements.txt (line 27)) (8.6.3)\n",
      "Requirement already satisfied: jupyter-core!=5.0.*,>=4.12 in .\\venv\\lib\\site-packages (from jupyter-server<3,>=2.4.0->notebook>=7.0.0->-r requirements.txt (line 27)) (5.8.1)\n",
      "Requirement already satisfied: jupyter-events>=0.11.0 in .\\venv\\lib\\site-packages (from jupyter-server<3,>=2.4.0->notebook>=7.0.0->-r requirements.txt (line 27)) (0.12.0)\n",
      "Requirement already satisfied: jupyter-server-terminals>=0.4.4 in .\\venv\\lib\\site-packages (from jupyter-server<3,>=2.4.0->notebook>=7.0.0->-r requirements.txt (line 27)) (0.5.3)\n",
      "Requirement already satisfied: nbformat>=5.3.0 in .\\venv\\lib\\site-packages (from jupyter-server<3,>=2.4.0->notebook>=7.0.0->-r requirements.txt (line 27)) (5.10.4)\n",
      "Requirement already satisfied: overrides>=5.0 in .\\venv\\lib\\site-packages (from jupyter-server<3,>=2.4.0->notebook>=7.0.0->-r requirements.txt (line 27)) (7.7.0)\n",
      "Requirement already satisfied: prometheus-client>=0.9 in .\\venv\\lib\\site-packages (from jupyter-server<3,>=2.4.0->notebook>=7.0.0->-r requirements.txt (line 27)) (0.22.1)\n",
      "Requirement already satisfied: pywinpty>=2.0.1 in .\\venv\\lib\\site-packages (from jupyter-server<3,>=2.4.0->notebook>=7.0.0->-r requirements.txt (line 27)) (2.0.15)\n",
      "Requirement already satisfied: pyzmq>=24 in .\\venv\\lib\\site-packages (from jupyter-server<3,>=2.4.0->notebook>=7.0.0->-r requirements.txt (line 27)) (27.0.1)\n",
      "Requirement already satisfied: send2trash>=1.8.2 in .\\venv\\lib\\site-packages (from jupyter-server<3,>=2.4.0->notebook>=7.0.0->-r requirements.txt (line 27)) (1.8.3)\n",
      "Requirement already satisfied: terminado>=0.8.3 in .\\venv\\lib\\site-packages (from jupyter-server<3,>=2.4.0->notebook>=7.0.0->-r requirements.txt (line 27)) (0.18.1)\n",
      "Requirement already satisfied: websocket-client>=1.7 in .\\venv\\lib\\site-packages (from jupyter-server<3,>=2.4.0->notebook>=7.0.0->-r requirements.txt (line 27)) (1.8.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in .\\venv\\lib\\site-packages (from jinja2->torch>=2.0.1->-r requirements.txt (line 9)) (3.0.2)\n",
      "Requirement already satisfied: async-lru>=1.0.0 in .\\venv\\lib\\site-packages (from jupyterlab->jupyter>=1.0.0->-r requirements.txt (line 26)) (2.0.5)\n",
      "Requirement already satisfied: httpx>=0.25.0 in .\\venv\\lib\\site-packages (from jupyterlab->jupyter>=1.0.0->-r requirements.txt (line 26)) (0.28.1)\n",
      "Requirement already satisfied: jupyter-lsp>=2.0.0 in .\\venv\\lib\\site-packages (from jupyterlab->jupyter>=1.0.0->-r requirements.txt (line 26)) (2.2.6)\n",
      "Requirement already satisfied: setuptools>=41.1.0 in .\\venv\\lib\\site-packages (from jupyterlab->jupyter>=1.0.0->-r requirements.txt (line 26)) (65.5.0)\n",
      "Requirement already satisfied: debugpy>=1.6.5 in .\\venv\\lib\\site-packages (from ipykernel->jupyter>=1.0.0->-r requirements.txt (line 26)) (1.8.16)\n",
      "Requirement already satisfied: nest-asyncio>=1.4 in .\\venv\\lib\\site-packages (from ipykernel->jupyter>=1.0.0->-r requirements.txt (line 26)) (1.6.0)\n",
      "Requirement already satisfied: babel>=2.10 in .\\venv\\lib\\site-packages (from jupyterlab-server<3,>=2.27.1->notebook>=7.0.0->-r requirements.txt (line 27)) (2.17.0)\n",
      "Requirement already satisfied: json5>=0.9.0 in .\\venv\\lib\\site-packages (from jupyterlab-server<3,>=2.27.1->notebook>=7.0.0->-r requirements.txt (line 27)) (0.12.0)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in .\\venv\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.72->langchain>=0.0.250->-r requirements.txt (line 36)) (1.33)\n",
      "Requirement already satisfied: orjson>=3.9.14 in .\\venv\\lib\\site-packages (from langsmith>=0.1.17->langchain>=0.0.250->-r requirements.txt (line 36)) (3.11.1)\n",
      "Requirement already satisfied: requests-toolbelt>=1.0.0 in .\\venv\\lib\\site-packages (from langsmith>=0.1.17->langchain>=0.0.250->-r requirements.txt (line 36)) (1.0.0)\n",
      "Requirement already satisfied: zstandard>=0.23.0 in .\\venv\\lib\\site-packages (from langsmith>=0.1.17->langchain>=0.0.250->-r requirements.txt (line 36)) (0.23.0)\n",
      "Requirement already satisfied: beautifulsoup4 in .\\venv\\lib\\site-packages (from nbconvert->jupyter>=1.0.0->-r requirements.txt (line 26)) (4.13.4)\n",
      "Requirement already satisfied: bleach!=5.0.0 in .\\venv\\lib\\site-packages (from bleach[css]!=5.0.0->nbconvert->jupyter>=1.0.0->-r requirements.txt (line 26)) (6.2.0)\n",
      "Requirement already satisfied: defusedxml in .\\venv\\lib\\site-packages (from nbconvert->jupyter>=1.0.0->-r requirements.txt (line 26)) (0.7.1)\n",
      "Requirement already satisfied: jupyterlab-pygments in .\\venv\\lib\\site-packages (from nbconvert->jupyter>=1.0.0->-r requirements.txt (line 26)) (0.3.0)\n",
      "Requirement already satisfied: mistune<4,>=2.0.3 in .\\venv\\lib\\site-packages (from nbconvert->jupyter>=1.0.0->-r requirements.txt (line 26)) (3.1.3)\n",
      "Requirement already satisfied: nbclient>=0.5.0 in .\\venv\\lib\\site-packages (from nbconvert->jupyter>=1.0.0->-r requirements.txt (line 26)) (0.10.2)\n",
      "Requirement already satisfied: pandocfilters>=1.4.1 in .\\venv\\lib\\site-packages (from nbconvert->jupyter>=1.0.0->-r requirements.txt (line 26)) (1.5.1)\n",
      "Requirement already satisfied: six>=1.5 in .\\venv\\lib\\site-packages (from python-dateutil>=2.8.2->pandas>=2.0.3->-r requirements.txt (line 2)) (1.17.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in .\\venv\\lib\\site-packages (from requests->transformers>=4.31.0->-r requirements.txt (line 8)) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in .\\venv\\lib\\site-packages (from requests->transformers>=4.31.0->-r requirements.txt (line 8)) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in .\\venv\\lib\\site-packages (from requests->transformers>=4.31.0->-r requirements.txt (line 8)) (2025.8.3)\n",
      "Requirement already satisfied: greenlet>=1 in .\\venv\\lib\\site-packages (from SQLAlchemy<3,>=1.4->langchain>=0.0.250->-r requirements.txt (line 36)) (3.2.4)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in .\\venv\\lib\\site-packages (from sympy>=1.13.3->torch>=2.0.1->-r requirements.txt (line 9)) (1.3.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in .\\venv\\lib\\site-packages (from anyio>=3.1.0->jupyter-server<3,>=2.4.0->notebook>=7.0.0->-r requirements.txt (line 27)) (1.3.1)\n",
      "Requirement already satisfied: argon2-cffi-bindings in .\\venv\\lib\\site-packages (from argon2-cffi>=21.1->jupyter-server<3,>=2.4.0->notebook>=7.0.0->-r requirements.txt (line 27)) (25.1.0)\n",
      "Requirement already satisfied: webencodings in .\\venv\\lib\\site-packages (from bleach!=5.0.0->bleach[css]!=5.0.0->nbconvert->jupyter>=1.0.0->-r requirements.txt (line 26)) (0.5.1)\n",
      "Requirement already satisfied: tinycss2<1.5,>=1.1.0 in .\\venv\\lib\\site-packages (from bleach[css]!=5.0.0->nbconvert->jupyter>=1.0.0->-r requirements.txt (line 26)) (1.4.0)\n",
      "Requirement already satisfied: cffi>=1.14 in .\\venv\\lib\\site-packages (from cryptography>=36.0.0->pdfminer.six==20250506->pdfplumber>=0.9.0->-r requirements.txt (line 22)) (1.17.1)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in .\\venv\\lib\\site-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit>=1.25.0->-r requirements.txt (line 37)) (5.0.2)\n",
      "Requirement already satisfied: httpcore==1.* in .\\venv\\lib\\site-packages (from httpx>=0.25.0->jupyterlab->jupyter>=1.0.0->-r requirements.txt (line 26)) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in .\\venv\\lib\\site-packages (from httpcore==1.*->httpx>=0.25.0->jupyterlab->jupyter>=1.0.0->-r requirements.txt (line 26)) (0.16.0)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.4 in .\\venv\\lib\\site-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets>=8.0.0->-r requirements.txt (line 28)) (0.8.4)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in .\\venv\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.72->langchain>=0.0.250->-r requirements.txt (line 36)) (3.0.0)\n",
      "Requirement already satisfied: attrs>=22.2.0 in .\\venv\\lib\\site-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit>=1.25.0->-r requirements.txt (line 37)) (25.3.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in .\\venv\\lib\\site-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit>=1.25.0->-r requirements.txt (line 37)) (2025.4.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in .\\venv\\lib\\site-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit>=1.25.0->-r requirements.txt (line 37)) (0.36.2)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in .\\venv\\lib\\site-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit>=1.25.0->-r requirements.txt (line 37)) (0.27.0)\n",
      "Requirement already satisfied: platformdirs>=2.5 in .\\venv\\lib\\site-packages (from jupyter-core!=5.0.*,>=4.12->jupyter-server<3,>=2.4.0->notebook>=7.0.0->-r requirements.txt (line 27)) (4.3.8)\n",
      "Requirement already satisfied: pywin32>=300 in .\\venv\\lib\\site-packages (from jupyter-core!=5.0.*,>=4.12->jupyter-server<3,>=2.4.0->notebook>=7.0.0->-r requirements.txt (line 27)) (311)\n",
      "Requirement already satisfied: python-json-logger>=2.0.4 in .\\venv\\lib\\site-packages (from jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->notebook>=7.0.0->-r requirements.txt (line 27)) (3.3.0)\n",
      "Requirement already satisfied: rfc3339-validator in .\\venv\\lib\\site-packages (from jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->notebook>=7.0.0->-r requirements.txt (line 27)) (0.1.4)\n",
      "Requirement already satisfied: rfc3986-validator>=0.1.1 in .\\venv\\lib\\site-packages (from jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->notebook>=7.0.0->-r requirements.txt (line 27)) (0.1.1)\n",
      "Requirement already satisfied: fastjsonschema>=2.15 in .\\venv\\lib\\site-packages (from nbformat>=5.3.0->jupyter-server<3,>=2.4.0->notebook>=7.0.0->-r requirements.txt (line 27)) (2.21.1)\n",
      "Requirement already satisfied: wcwidth in .\\venv\\lib\\site-packages (from prompt_toolkit<3.1.0,>=3.0.41->ipython>=6.1.0->ipywidgets>=8.0.0->-r requirements.txt (line 28)) (0.2.13)\n",
      "Requirement already satisfied: soupsieve>1.2 in .\\venv\\lib\\site-packages (from beautifulsoup4->nbconvert->jupyter>=1.0.0->-r requirements.txt (line 26)) (2.7)\n",
      "Requirement already satisfied: executing>=1.2.0 in .\\venv\\lib\\site-packages (from stack_data->ipython>=6.1.0->ipywidgets>=8.0.0->-r requirements.txt (line 28)) (2.2.0)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in .\\venv\\lib\\site-packages (from stack_data->ipython>=6.1.0->ipywidgets>=8.0.0->-r requirements.txt (line 28)) (3.0.0)\n",
      "Requirement already satisfied: pure-eval in .\\venv\\lib\\site-packages (from stack_data->ipython>=6.1.0->ipywidgets>=8.0.0->-r requirements.txt (line 28)) (0.2.3)\n",
      "Requirement already satisfied: pycparser in .\\venv\\lib\\site-packages (from cffi>=1.14->cryptography>=36.0.0->pdfminer.six==20250506->pdfplumber>=0.9.0->-r requirements.txt (line 22)) (2.22)\n",
      "Requirement already satisfied: fqdn in .\\venv\\lib\\site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->notebook>=7.0.0->-r requirements.txt (line 27)) (1.5.1)\n",
      "Requirement already satisfied: isoduration in .\\venv\\lib\\site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->notebook>=7.0.0->-r requirements.txt (line 27)) (20.11.0)\n",
      "Requirement already satisfied: rfc3987-syntax>=1.1.0 in .\\venv\\lib\\site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->notebook>=7.0.0->-r requirements.txt (line 27)) (1.1.0)\n",
      "Requirement already satisfied: uri-template in .\\venv\\lib\\site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->notebook>=7.0.0->-r requirements.txt (line 27)) (1.3.0)\n",
      "Requirement already satisfied: webcolors>=24.6.0 in .\\venv\\lib\\site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->notebook>=7.0.0->-r requirements.txt (line 27)) (24.11.1)\n",
      "Requirement already satisfied: lark>=1.2.2 in .\\venv\\lib\\site-packages (from rfc3987-syntax>=1.1.0->jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->notebook>=7.0.0->-r requirements.txt (line 27)) (1.2.2)\n",
      "Requirement already satisfied: arrow>=0.15.0 in .\\venv\\lib\\site-packages (from isoduration->jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->notebook>=7.0.0->-r requirements.txt (line 27)) (1.3.0)\n",
      "Requirement already satisfied: types-python-dateutil>=2.8.10 in .\\venv\\lib\\site-packages (from arrow>=0.15.0->isoduration->jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->notebook>=7.0.0->-r requirements.txt (line 27)) (2.9.0.20250708)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 25.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d37e5c97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîÑ Importing project modules...\n",
      "‚úÖ Imported 10 modules successfully\n",
      "2025-08-09 01:16:02,397 - __main__ - INFO - Starting Financial Bot Setup Tests...\n",
      "================================================================================\n",
      "üöÄ STARTING COMPREHENSIVE AGENTIC FINANCIAL AI TESTING\n",
      "================================================================================\n",
      "\n",
      "============================================================\n",
      "üìã PHASE 1: SYSTEM COMPONENT TESTING\n",
      "============================================================\n",
      "\n",
      "üîß Running Advanced System Validation Tests...\n",
      "‚úÖ Test CSV created at: f:\\agentic-ai\\data\\test_budget.csv\n",
      "2025-08-09 01:16:02,400 - root - INFO - Testing system requirements...\n",
      "2025-08-09 01:16:02,400 - root - WARNING - CUDA is not available. Using CPU (this will be slower)\n",
      "2025-08-09 01:16:02,404 - root - INFO - Downloading and setting up models...\n",
      "2025-08-09 01:16:02,404 - root - INFO - Downloading gpt2 model...\n",
      "2025-08-09 01:16:02,955 - root - INFO - Downloading distilbert model...\n",
      "2025-08-09 01:16:03,285 - root - INFO - Testing model initialization...\n",
      "2025-08-09 01:16:03,285 - llms.gpt2_wrapper - INFO - Initializing GPT-2 model from gpt2\n",
      "2025-08-09 01:16:05,664 - llms.gpt2_wrapper - INFO - Successfully loaded GPT-2 model\n",
      "2025-08-09 01:16:05,666 - root - INFO - ‚úÖ GPT2Wrapper initialized successfully\n",
      "2025-08-09 01:16:05,666 - llms.distilbert_wrapper - INFO - Initializing DistilBERT model from distilbert-base-uncased\n",
      "2025-08-09 01:16:09,786 - llms.distilbert_wrapper - INFO - Successfully loaded DistilBERT model\n",
      "2025-08-09 01:16:09,786 - root - INFO - ‚úÖ DistilBertWrapper initialized successfully\n",
      "2025-08-09 01:16:09,786 - root - INFO - ‚úÖ FinancialAgent created successfully with mock LLM\n",
      "2025-08-09 01:16:09,786 - root - INFO - ‚úÖ Model initialization tests completed\n",
      "2025-08-09 01:16:09,796 - root - INFO - Testing file processing...\n",
      "2025-08-09 01:16:09,797 - parsers.csv_parser - INFO - Successfully read with encoding=utf-8, separator=','\n",
      "2025-08-09 01:16:09,798 - parsers.csv_parser - INFO - Successfully read CSV with 10 rows and 3 columns\n",
      "2025-08-09 01:16:09,805 - utils.file_loader - INFO - Successfully validated 10 transactions from f:\\agentic-ai\\data\\test_budget.csv\n",
      "2025-08-09 01:16:09,805 - root - INFO - Testing basic financial analysis...\n",
      "2025-08-09 01:16:09,806 - parsers.csv_parser - INFO - Successfully read with encoding=utf-8, separator=','\n",
      "2025-08-09 01:16:09,806 - parsers.csv_parser - INFO - Successfully read CSV with 10 rows and 3 columns\n",
      "2025-08-09 01:16:09,810 - utils.file_loader - INFO - Successfully validated 10 transactions from f:\\agentic-ai\\data\\test_budget.csv\n",
      "2025-08-09 01:16:09,810 - root - INFO - ‚úÖ Agent has run method available\n",
      "2025-08-09 01:16:09,810 - root - INFO - ‚úÖ Basic analysis test completed successfully\n",
      "   Advanced Tests: 5/5 passed\n",
      "\n",
      "üîß Running Basic Component Tests...\n",
      "2025-08-09 01:16:09,810 - __main__ - INFO - Testing module imports...\n",
      "2025-08-09 01:16:09,877 - __main__ - INFO - ‚úÖ All imports successful\n",
      "   ‚úÖ test_imports\n",
      "2025-08-09 01:16:09,877 - __main__ - INFO - Testing FileLoader initialization...\n",
      "2025-08-09 01:16:09,877 - __main__ - INFO - ‚úÖ FileLoader initialization successful\n",
      "   ‚úÖ test_file_loader_initialization\n",
      "2025-08-09 01:16:09,877 - __main__ - INFO - Testing parser initializations...\n",
      "2025-08-09 01:16:09,877 - __main__ - INFO - ‚úÖ Parser initialization successful\n",
      "   ‚úÖ test_parser_initialization\n",
      "2025-08-09 01:16:09,877 - __main__ - INFO - Testing analyzer initializations...\n",
      "2025-08-09 01:16:09,877 - __main__ - INFO - ‚úÖ Analyzer initialization successful\n",
      "   ‚úÖ test_analyzer_initialization\n",
      "2025-08-09 01:16:09,877 - __main__ - INFO - Testing chart generator initialization...\n",
      "2025-08-09 01:16:09,877 - __main__ - INFO - ‚úÖ Chart generator object created successfully\n",
      "   ‚úÖ test_chart_generator_initialization\n",
      "2025-08-09 01:16:09,878 - __main__ - INFO - Testing directory structure...\n",
      "2025-08-09 01:16:09,878 - __main__ - INFO - ‚úÖ Directory structure validation successful\n",
      "   ‚úÖ test_directory_structure\n",
      "2025-08-09 01:16:09,878 - __main__ - INFO - Testing logging setup...\n",
      "2025-08-09 01:16:09,878 - __main__ - INFO - Test logging message\n",
      "2025-08-09 01:16:09,878 - __main__ - INFO - ‚úÖ Logging setup successful\n",
      "   ‚úÖ test_logging_setup\n",
      "\n",
      "‚úÖ PHASE 1 COMPLETED: 100.0% success rate\n",
      "\n",
      "============================================================\n",
      "ü§ñ PHASE 2: MODEL LOADING AND SAMPLE DATA CREATION\n",
      "============================================================\n",
      "2025-08-09 01:16:09,878 - __main__ - INFO - Testing model loading...\n",
      "2025-08-09 01:16:09,878 - __main__ - INFO - ‚úÖ Model wrapper imports successful\n",
      "   ‚úÖ test_model_loading\n",
      "2025-08-09 01:16:09,878 - __main__ - INFO - Creating sample CSV data...\n",
      "2025-08-09 01:16:09,880 - __main__ - INFO - ‚úÖ Sample CSV created: data/input\\test_financial_data.csv with 100 transactions\n",
      "   ‚úÖ create_sample_csv_data\n",
      "2025-08-09 01:16:09,880 - __main__ - INFO - Creating test questions...\n",
      "2025-08-09 01:16:09,881 - __main__ - INFO - ‚úÖ Test questions created: 8 questions\n",
      "   ‚úÖ create_test_questions\n",
      "2025-08-09 01:16:09,881 - __main__ - INFO - Testing data file creation...\n",
      "2025-08-09 01:16:09,881 - __main__ - INFO - ‚úÖ Data file creation validation successful\n",
      "   ‚úÖ test_data_file_creation\n",
      "2025-08-09 01:16:09,881 - __main__ - INFO - Testing file parsing...\n",
      "2025-08-09 01:16:09,897 - parsers.csv_parser - INFO - Successfully read with encoding=utf-8, separator=','\n",
      "2025-08-09 01:16:09,897 - parsers.csv_parser - INFO - Successfully read CSV with 100 rows and 4 columns\n",
      "2025-08-09 01:16:09,902 - utils.file_loader - INFO - Successfully validated 100 transactions from data/input\\test_financial_data.csv\n",
      "2025-08-09 01:16:09,902 - __main__ - INFO - File parsing successful: 100 records parsed\n",
      "   ‚úÖ test_file_parsing\n",
      "\n",
      "‚úÖ PHASE 2 COMPLETED: 100.0% success rate\n",
      "\n",
      "============================================================\n",
      "üß† PHASE 3: LLM INTEGRATION AND JOB ASSIGNMENT TESTING\n",
      "============================================================\n",
      "2025-08-09 01:16:09,903 - __main__ - INFO - Testing agent initialization...\n",
      "2025-08-09 01:16:09,903 - __main__ - INFO - ‚úÖ FinancialAgent initialized successfully\n",
      "2025-08-09 01:16:09,903 - __main__ - INFO - ‚úÖ FinancialAgentSimplified initialized successfully\n",
      "2025-08-09 01:16:09,903 - __main__ - INFO - ‚úÖ Agent initialization successful\n",
      "   ‚úÖ test_agent_initialization\n",
      "2025-08-09 01:16:09,903 - __main__ - INFO - Testing data loading with agents...\n",
      "2025-08-09 01:16:09,904 - parsers.csv_parser - INFO - Successfully read with encoding=utf-8, separator=','\n",
      "2025-08-09 01:16:09,904 - parsers.csv_parser - INFO - Successfully read CSV with 100 rows and 4 columns\n",
      "2025-08-09 01:16:09,910 - utils.file_loader - INFO - Successfully validated 100 transactions from data/input\\test_financial_data.csv\n",
      "2025-08-09 01:16:09,910 - __main__ - INFO - ‚úÖ Agent created successfully (no load_data method)\n",
      "2025-08-09 01:16:09,910 - __main__ - INFO - ‚úÖ Data loading with agents successful\n",
      "   ‚úÖ test_data_loading_with_agents\n",
      "2025-08-09 01:16:09,910 - __main__ - INFO - Testing budget analysis job...\n",
      "2025-08-09 01:16:09,911 - parsers.csv_parser - INFO - Successfully read with encoding=utf-8, separator=','\n",
      "2025-08-09 01:16:09,911 - parsers.csv_parser - INFO - Successfully read CSV with 100 rows and 4 columns\n",
      "2025-08-09 01:16:09,917 - utils.file_loader - INFO - Successfully validated 100 transactions from data/input\\test_financial_data.csv\n",
      "2025-08-09 01:16:09,917 - __main__ - INFO - ‚úÖ Budget analysis job successful (Time: 0.01s)\n",
      "   ‚úÖ test_budget_analysis_job\n",
      "2025-08-09 01:16:09,917 - __main__ - INFO - Testing trend analysis job...\n",
      "2025-08-09 01:16:09,919 - parsers.csv_parser - INFO - Successfully read with encoding=utf-8, separator=','\n",
      "2025-08-09 01:16:09,919 - parsers.csv_parser - INFO - Successfully read CSV with 100 rows and 4 columns\n",
      "2025-08-09 01:16:09,924 - utils.file_loader - INFO - Successfully validated 100 transactions from data/input\\test_financial_data.csv\n",
      "2025-08-09 01:16:09,946 - __main__ - INFO - ‚úÖ Trend analysis job successful (Time: 0.03s)\n",
      "   ‚úÖ test_trend_analysis_job\n",
      "2025-08-09 01:16:09,946 - __main__ - INFO - Testing category analysis job...\n",
      "2025-08-09 01:16:09,947 - parsers.csv_parser - INFO - Successfully read with encoding=utf-8, separator=','\n",
      "2025-08-09 01:16:09,947 - parsers.csv_parser - INFO - Successfully read CSV with 100 rows and 4 columns\n",
      "2025-08-09 01:16:09,952 - utils.file_loader - INFO - Successfully validated 100 transactions from data/input\\test_financial_data.csv\n",
      "2025-08-09 01:16:09,953 - __main__ - INFO - ‚úÖ Category analysis job successful (Time: 0.01s)\n",
      "   ‚úÖ test_category_analysis_job\n",
      "2025-08-09 01:16:09,953 - __main__ - INFO - Testing performance metrics...\n",
      "2025-08-09 01:16:09,953 - __main__ - INFO - ‚úÖ Performance metrics: {'total_metrics_recorded': 3, 'average_processing_time': 0.014476378758748373}\n",
      "   ‚úÖ test_performance_metrics\n",
      "2025-08-09 01:16:09,953 - __main__ - INFO - Testing multi-agent collaboration...\n",
      "2025-08-09 01:16:09,954 - parsers.csv_parser - INFO - Successfully read with encoding=utf-8, separator=','\n",
      "2025-08-09 01:16:09,954 - parsers.csv_parser - INFO - Successfully read CSV with 100 rows and 4 columns\n",
      "2025-08-09 01:16:09,960 - utils.file_loader - INFO - Successfully validated 100 transactions from data/input\\test_financial_data.csv\n",
      "2025-08-09 01:16:09,960 - __main__ - INFO - ‚úÖ Both agents initialized and can access data\n",
      "2025-08-09 01:16:09,960 - __main__ - INFO - ‚úÖ Multi-agent collaboration successful\n",
      "   ‚úÖ test_multi_agent_collaboration\n",
      "\n",
      "‚úÖ PHASE 3 COMPLETED: 100.0% success rate\n",
      "\n",
      "============================================================\n",
      "üßπ CLEANUP: REMOVING TEST DATA AND MEMORY\n",
      "============================================================\n",
      "2025-08-09 01:16:09,960 - __main__ - INFO - Removed: data/input\\test_financial_data.csv\n",
      "2025-08-09 01:16:09,961 - __main__ - INFO - Removed: data/input\\test_questions.txt\n",
      "2025-08-09 01:16:09,961 - __main__ - INFO - Removed empty directory: data/input\n",
      "2025-08-09 01:16:09,961 - __main__ - INFO - ‚úÖ Cleanup completed successfully\n",
      "\n",
      "================================================================================\n",
      "üìä FINAL TEST RESULTS SUMMARY\n",
      "================================================================================\n",
      "\n",
      "üéØ OVERALL RESULTS:\n",
      "   Total Tests: 24\n",
      "   ‚úÖ Passed: 24\n",
      "   ‚ùå Failed: 0\n",
      "   Success Rate: 100.0%\n",
      "   Total Execution Time: 7.56s\n",
      "\n",
      "üìã PHASE 1:\n",
      "   ‚úÖ Passed: 12\n",
      "   ‚ùå Failed: 0\n",
      "   Details:\n",
      "     - Module imports: PASSED\n",
      "     - FileLoader initialization: PASSED\n",
      "     - Parser initialization: PASSED\n",
      "     - Analyzer initialization: PASSED\n",
      "     - Chart generator initialization: PASSED\n",
      "\n",
      "üìã PHASE 2:\n",
      "   ‚úÖ Passed: 5\n",
      "   ‚ùå Failed: 0\n",
      "   Details:\n",
      "     - Model loading: PASSED\n",
      "     - Sample CSV creation: PASSED (100 transactions)\n",
      "     - Test questions creation: PASSED (8 questions)\n",
      "     - Data file creation: PASSED\n",
      "     - File parsing: PASSED (100 records)\n",
      "\n",
      "üìã PHASE 3:\n",
      "   ‚úÖ Passed: 7\n",
      "   ‚ùå Failed: 0\n",
      "   Details:\n",
      "     - Agent initialization: PASSED\n",
      "     - Data loading with agents: PASSED\n",
      "     - Budget analysis job: PASSED (Time: 0.01s)\n",
      "     - Trend analysis job: PASSED (Time: 0.03s)\n",
      "     - Category analysis job: PASSED (Time: 0.01s)\n",
      "\n",
      "üéâ ALL TESTS COMPLETED SUCCESSFULLY!\n",
      "================================================================================\n",
      "2025-08-09 01:16:09,962 - __main__ - INFO - \n",
      "‚úÖ All tests passed! The Financial Bot is ready to use.\n",
      "2025-08-09 01:16:09,962 - __main__ - INFO - \n",
      "You can now run the main notebook (main.ipynb)\n",
      "\n",
      "üöÄ SETUP COMPLETE - Financial AI Assistant is ready!\n",
      "\n",
      "============================================================\n",
      "Testing session completed.\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n",
      "f:\\agentic-ai\\analysis\\trend_analyzer.py:42: FutureWarning:\n",
      "\n",
      "'M' is deprecated and will be removed in a future version, please use 'ME' instead.\n",
      "\n",
      "f:\\agentic-ai\\analysis\\trend_analyzer.py:55: FutureWarning:\n",
      "\n",
      "'M' is deprecated and will be removed in a future version, please use 'ME' instead.\n",
      "\n",
      "f:\\agentic-ai\\analysis\\trend_analyzer.py:75: FutureWarning:\n",
      "\n",
      "DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!python test_setup.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6688162d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÅ Current working directory: f:\\agentic-ai\n",
      "üêç Python path includes: f:\\agentic-ai\n",
      "‚úì Core libraries imported successfully!\n",
      "\n",
      "üîç Checking project modules...\n",
      "‚úì Core libraries imported successfully!\n",
      "\n",
      "üîç Checking project modules...\n",
      "   FinancialAgent: ‚úì\n",
      "   LLM Wrappers: ‚úì\n",
      "   Analysis Modules: ‚úì\n",
      "   Visualization Modules: ‚úì\n",
      "   File Processing: ‚úì\n",
      "\n",
      "üìä Import Summary: 5/5 module groups imported successfully\n",
      "üéâ All modules imported successfully! You can proceed with the financial analysis.\n",
      "   FinancialAgent: ‚úì\n",
      "   LLM Wrappers: ‚úì\n",
      "   Analysis Modules: ‚úì\n",
      "   Visualization Modules: ‚úì\n",
      "   File Processing: ‚úì\n",
      "\n",
      "üìä Import Summary: 5/5 module groups imported successfully\n",
      "üéâ All modules imported successfully! You can proceed with the financial analysis.\n"
     ]
    }
   ],
   "source": [
    "# ========================================\n",
    "# 1. INITIALIZE LIBRARIES AND DEPENDENCIES\n",
    "# ========================================\n",
    "\n",
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Get the current working directory and add it to Python path\n",
    "current_dir = os.getcwd()\n",
    "if current_dir not in sys.path:\n",
    "    sys.path.insert(0, current_dir)\n",
    "\n",
    "# Also add parent directory if needed\n",
    "parent_dir = str(Path(current_dir).parent)\n",
    "if parent_dir not in sys.path:\n",
    "    sys.path.insert(0, parent_dir)\n",
    "\n",
    "print(f\"üìÅ Current working directory: {current_dir}\")\n",
    "print(f\"üêç Python path includes: {current_dir}\")\n",
    "\n",
    "# Core libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "print(\"‚úì Core libraries imported successfully!\")\n",
    "\n",
    "# Check if project modules are available before importing\n",
    "def check_and_import_modules():\n",
    "    \"\"\"Check if project modules exist and import them safely\"\"\"\n",
    "    modules_status = {}\n",
    "    \n",
    "    try:\n",
    "        # Check if agents directory exists\n",
    "        if os.path.exists(os.path.join(current_dir, 'agents')):\n",
    "            from agents.financial_agent import FinancialAgent\n",
    "            modules_status['FinancialAgent'] = '‚úì'\n",
    "        else:\n",
    "            modules_status['FinancialAgent'] = '‚ùå agents/ directory not found'\n",
    "    except ImportError as e:\n",
    "        modules_status['FinancialAgent'] = f'‚ùå {str(e)}'\n",
    "    \n",
    "    try:\n",
    "        # Check if llms directory exists\n",
    "        if os.path.exists(os.path.join(current_dir, 'llms')):\n",
    "            from llms.gpt2_wrapper import GPT2Wrapper\n",
    "            from llms.distilbert_wrapper import DistilBertWrapper\n",
    "            modules_status['LLM Wrappers'] = '‚úì'\n",
    "        else:\n",
    "            modules_status['LLM Wrappers'] = '‚ùå llms/ directory not found'\n",
    "    except ImportError as e:\n",
    "        modules_status['LLM Wrappers'] = f'‚ùå {str(e)}'\n",
    "    \n",
    "    try:\n",
    "        # Analysis modules\n",
    "        if os.path.exists(os.path.join(current_dir, 'analysis')):\n",
    "            from analysis.budget_calculator import BudgetCalculator\n",
    "            from analysis.trend_analyzer import TrendAnalyzer\n",
    "            modules_status['Analysis Modules'] = '‚úì'\n",
    "        else:\n",
    "            modules_status['Analysis Modules'] = '‚ùå analysis/ directory not found'\n",
    "    except ImportError as e:\n",
    "        modules_status['Analysis Modules'] = f'‚ùå {str(e)}'\n",
    "    \n",
    "    try:\n",
    "        # Visualization modules\n",
    "        if os.path.exists(os.path.join(current_dir, 'visualizations')):\n",
    "            from visualizations.chart_generator import ChartGenerator\n",
    "            modules_status['Visualization Modules'] = '‚úì'\n",
    "        else:\n",
    "            modules_status['Visualization Modules'] = '‚ùå visualizations/ directory not found'\n",
    "    except ImportError as e:\n",
    "        modules_status['Visualization Modules'] = f'‚ùå {str(e)}'\n",
    "    \n",
    "    try:\n",
    "        # File processing modules\n",
    "        if os.path.exists(os.path.join(current_dir, 'parsers')) and os.path.exists(os.path.join(current_dir, 'utils')):\n",
    "            from parsers.csv_parser import CSVParser\n",
    "            from parsers.pdf_parser import PDFParser\n",
    "            from utils.file_loader import FileLoader\n",
    "            from utils.helpers import Helpers\n",
    "            modules_status['File Processing'] = '‚úì'\n",
    "        else:\n",
    "            missing = []\n",
    "            if not os.path.exists(os.path.join(current_dir, 'parsers')):\n",
    "                missing.append('parsers/')\n",
    "            if not os.path.exists(os.path.join(current_dir, 'utils')):\n",
    "                missing.append('utils/')\n",
    "            modules_status['File Processing'] = f'‚ùå Missing directories: {\", \".join(missing)}'\n",
    "    except ImportError as e:\n",
    "        modules_status['File Processing'] = f'‚ùå {str(e)}'\n",
    "    \n",
    "    return modules_status\n",
    "\n",
    "# Check module imports\n",
    "print(\"\\nüîç Checking project modules...\")\n",
    "modules_status = check_and_import_modules()\n",
    "\n",
    "for module_group, status in modules_status.items():\n",
    "    print(f\"   {module_group}: {status}\")\n",
    "\n",
    "# Count successful imports\n",
    "successful_imports = sum(1 for status in modules_status.values() if status == '‚úì')\n",
    "total_modules = len(modules_status)\n",
    "\n",
    "print(f\"\\nüìä Import Summary: {successful_imports}/{total_modules} module groups imported successfully\")\n",
    "\n",
    "if successful_imports == total_modules:\n",
    "    print(\"üéâ All modules imported successfully! You can proceed with the financial analysis.\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è  Some modules failed to import. You may need to:\")\n",
    "    print(\"   1. Make sure you're in the correct project directory\")\n",
    "    print(\"   2. Check that all project files are present\")\n",
    "    print(\"   3. Run the test_setup.py script first to validate the setup\")\n",
    "    print(f\"\\nüí° Current directory structure:\")\n",
    "    for item in os.listdir(current_dir):\n",
    "        if os.path.isdir(os.path.join(current_dir, item)):\n",
    "            print(f\"   üìÅ {item}/\")\n",
    "        else:\n",
    "            print(f\"   üìÑ {item}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "49bec472",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üì¶ Checking dependencies...\n",
      "--------------------------------------------------\n",
      "üì¶ Package Status:\n",
      "--------------------------------------------------\n",
      "‚úÖ pandas - Data manipulation and analysis\n",
      "‚úÖ numpy - Numerical computations\n",
      "‚úÖ matplotlib - Basic plotting\n",
      "‚úÖ plotly - Interactive visualizations\n",
      "‚úÖ transformers - AI model support\n",
      "‚úÖ torch - PyTorch for AI models\n",
      "‚úÖ PyPDF2 - PDF file processing\n",
      "‚úÖ openpyxl - Excel file support\n",
      "‚úÖ scipy - Scientific computing\n",
      "‚úÖ scikit-learn - Machine learning utilities\n",
      "\n",
      "üì¶ Optional Packages:\n",
      "‚úÖ pdfplumber - Advanced PDF parsing\n",
      "‚úÖ tabula - PDF table extraction\n",
      "‚úÖ openpyxl - Excel file support\n",
      "‚úÖ scipy - Scientific computing\n",
      "‚úÖ scikit-learn - Machine learning utilities\n",
      "\n",
      "üì¶ Optional Packages:\n",
      "‚úÖ pdfplumber - Advanced PDF parsing\n",
      "‚úÖ tabula - PDF table extraction\n",
      "‚úÖ seaborn - Statistical visualization\n",
      "\n",
      "üéâ All required dependencies are installed!\n",
      "\n",
      "‚úÖ Dependencies verified - Ready to proceed!\n",
      "‚úÖ seaborn - Statistical visualization\n",
      "\n",
      "üéâ All required dependencies are installed!\n",
      "\n",
      "‚úÖ Dependencies verified - Ready to proceed!\n"
     ]
    }
   ],
   "source": [
    "# ========================================\n",
    "# 2. DEPENDENCY VALIDATION\n",
    "# ========================================\n",
    "\n",
    "def check_dependencies():\n",
    "    \"\"\"Check if all required packages are installed\"\"\"\n",
    "    \n",
    "    print(\"üì¶ Checking dependencies...\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    required_packages = {\n",
    "        'pandas': 'Data manipulation and analysis',\n",
    "        'numpy': 'Numerical computations',\n",
    "        'matplotlib': 'Basic plotting',\n",
    "        'plotly': 'Interactive visualizations',\n",
    "        'transformers': 'AI model support',\n",
    "        'torch': 'PyTorch for AI models',\n",
    "        'PyPDF2': 'PDF file processing',\n",
    "        'openpyxl': 'Excel file support',\n",
    "        'scipy': 'Scientific computing',\n",
    "        'scikit-learn': 'Machine learning utilities'\n",
    "    }\n",
    "    \n",
    "    optional_packages = {\n",
    "        'pdfplumber': 'Advanced PDF parsing',\n",
    "        'tabula': 'PDF table extraction',\n",
    "        'seaborn': 'Statistical visualization'\n",
    "    }\n",
    "    \n",
    "    missing_packages = []\n",
    "    installed_packages = []\n",
    "    \n",
    "    print(\"üì¶ Package Status:\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    # Check required packages\n",
    "    for package, description in required_packages.items():\n",
    "        try:\n",
    "            if package == 'scikit-learn':\n",
    "                import sklearn\n",
    "            elif package == 'PyPDF2':\n",
    "                import PyPDF2\n",
    "            else:\n",
    "                __import__(package)\n",
    "            print(f\"‚úÖ {package} - {description}\")\n",
    "            installed_packages.append(package)\n",
    "        except ImportError:\n",
    "            print(f\"‚ùå {package} - {description}\")\n",
    "            missing_packages.append(package)\n",
    "    \n",
    "    # Check optional packages\n",
    "    if any(optional_packages):\n",
    "        print(f\"\\nüì¶ Optional Packages:\")\n",
    "        for package, description in optional_packages.items():\n",
    "            try:\n",
    "                __import__(package)\n",
    "                print(f\"‚úÖ {package} - {description}\")\n",
    "            except ImportError:\n",
    "                print(f\"‚ö†Ô∏è  {package} - {description} (optional)\")\n",
    "    \n",
    "    # Summary\n",
    "    if missing_packages:\n",
    "        print(f\"\\n‚ö†Ô∏è  Missing Critical Packages:\")\n",
    "        for package in missing_packages:\n",
    "            print(f\"‚ùå {package} - {required_packages[package]}\")\n",
    "        \n",
    "        print(f\"\\nüí° To install missing packages, run in terminal:\")\n",
    "        print(f\"   pip install {' '.join(missing_packages)}\")\n",
    "        print(f\"\\n   Or install everything from requirements.txt:\")\n",
    "        print(f\"   pip install -r requirements.txt\")\n",
    "        \n",
    "        return False\n",
    "    else:\n",
    "        print(f\"\\nüéâ All required dependencies are installed!\")\n",
    "        return True\n",
    "\n",
    "# Run dependency check\n",
    "dependencies_ok = check_dependencies()\n",
    "\n",
    "if not dependencies_ok:\n",
    "    print(f\"\\nüõë Please install missing packages and restart the notebook.\")\n",
    "    print(f\"üí° You can continue with limited functionality, but some features may not work.\")\n",
    "else:\n",
    "    print(f\"\\n‚úÖ Dependencies verified - Ready to proceed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8bb071e",
   "metadata": {},
   "source": [
    "# 2. Initialize AI Models\n",
    "\n",
    "Loading the language models that will power the financial assistant:\n",
    "\n",
    "- **GPT-2**: Primary model for text generation and conversational AI\n",
    "- **DistilBERT**: Lightweight model for specific analysis tasks\n",
    "\n",
    "These models run locally without requiring authentication or internet access."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10ad3561",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================================\n",
    "# 2. INITIALIZE AI MODELS\n",
    "# ========================================\n",
    "\n",
    "print(\"ü§ñ Initializing AI Models...\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "# Initialize GPT-2 model\n",
    "print(\"Loading GPT-2 model...\")\n",
    "try:\n",
    "    gpt2_model = GPT2Wrapper(\"gpt2\")\n",
    "    print(\"‚úì GPT-2 model loaded successfully!\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error loading GPT-2: {e}\")\n",
    "    gpt2_model = None\n",
    "\n",
    "# Initialize DistilBERT model  \n",
    "print(\"Loading DistilBERT model...\")\n",
    "try:\n",
    "    distilbert_model = DistilBertWrapper(\"distilbert-base-uncased\")\n",
    "    print(\"‚úì DistilBERT model loaded successfully!\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error loading DistilBERT: {e}\")\n",
    "    distilbert_model = None\n",
    "\n",
    "# Create financial agents\n",
    "print(\"Creating financial agents...\")\n",
    "if gpt2_model:\n",
    "    gpt2_agent = FinancialAgent(gpt2_model)\n",
    "    print(\"‚úì GPT-2 Financial Agent ready!\")\n",
    "\n",
    "if distilbert_model:\n",
    "    distilbert_agent = FinancialAgent(distilbert_model)\n",
    "    print(\"‚úì DistilBERT Financial Agent ready!\")\n",
    "\n",
    "# Initialize analysis components\n",
    "budget_calc = BudgetCalculator()\n",
    "trend_analyzer = TrendAnalyzer()\n",
    "chart_gen = ChartGenerator()\n",
    "file_loader = FileLoader()\n",
    "\n",
    "print(\"‚úì All components initialized successfully!\")\n",
    "print(\"=\" * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55be1b4c",
   "metadata": {},
   "source": [
    "# 3. RAG-Based Data Input\n",
    "\n",
    "This system works as a **RAG (Retrieval Augmented Generation) model** that analyzes only your uploaded financial data.\n",
    "\n",
    "## Supported Formats:\n",
    "- **CSV files**: Must contain columns for date, amount, and category/description\n",
    "- **PDF files**: Bank statements and financial reports (with intelligent parsing)\n",
    "\n",
    "## RAG Model Features:\n",
    "- üîç **Intelligent Data Discovery**: Automatically detects and maps your data columns\n",
    "- üìä **Quality Assessment**: Validates data completeness and suggests improvements  \n",
    "- ü§ñ **Context-Aware Analysis**: LLM analyzes patterns found in YOUR specific data\n",
    "- üí¨ **Conversational Interface**: Ask questions about your actual financial data\n",
    "\n",
    "## Required CSV Structure:\n",
    "Your CSV should contain financial transaction data with columns like:\n",
    "- **Date column**: Transaction dates (auto-detected format)\n",
    "- **Amount column**: Transaction amounts (positive/negative values)\n",
    "- **Category/Description**: Spending categories or transaction descriptions\n",
    "\n",
    "> **Note**: The system intelligently detects column names and data patterns. Column names can be flexible (e.g., 'date', 'transaction_date', 'amount', 'value', 'category', 'description', etc.)\n",
    "\n",
    "## How it works:\n",
    "1. Upload your actual financial data (CSV/PDF)\n",
    "2. System intelligently parses and validates your data\n",
    "3. LLM learns from your specific spending patterns\n",
    "4. Ask questions and get insights based on YOUR data only"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afeca956",
   "metadata": {},
   "source": [
    "# 4. Data Processing & Analysis\n",
    "\n",
    "Once your data is loaded, we'll process it through multiple analysis stages:\n",
    "\n",
    "1. **Data Validation**: Ensure proper format and clean any inconsistencies\n",
    "2. **Budget Calculation**: Analyze spending patterns by category\n",
    "3. **Trend Analysis**: Identify spending trends over time\n",
    "4. **Financial Health Check**: Calculate savings rate and financial ratios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "055d2753",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================================\n",
    "# 3. DATA INPUT AND LOADING\n",
    "# ========================================\n",
    "\n",
    "print(\"üìÅ Setting up data input...\")\n",
    "\n",
    "# Get current working directory and ensure we're in the right place\n",
    "current_dir = os.getcwd()\n",
    "print(f\"üìç Current directory: {current_dir}\")\n",
    "\n",
    "# Smart directory detection for different environments\n",
    "def setup_data_directories():\n",
    "    \"\"\"Setup data directories with smart path detection\"\"\"\n",
    "    \n",
    "    # Check if we're already in the project directory\n",
    "    if os.path.exists('agents') and os.path.exists('parsers'):\n",
    "        base_dir = current_dir\n",
    "        print(\"‚úÖ Found project directory structure\")\n",
    "    else:\n",
    "        # Look for project in common locations\n",
    "        possible_locations = [\n",
    "            'agentic-ai',\n",
    "            '../agentic-ai', \n",
    "            './agentic-ai',\n",
    "            'financial-agentic-ai',\n",
    "            '../financial-agentic-ai'\n",
    "        ]\n",
    "        \n",
    "        base_dir = None\n",
    "        for location in possible_locations:\n",
    "            if os.path.exists(location) and os.path.exists(os.path.join(location, 'agents')):\n",
    "                base_dir = os.path.abspath(location)\n",
    "                print(f\"‚úÖ Found project at: {base_dir}\")\n",
    "                break\n",
    "        \n",
    "        if not base_dir:\n",
    "            print(\"‚ùå Project directory not found!\")\n",
    "            print(\"üìÇ Available directories:\")\n",
    "            for item in os.listdir('.'):\n",
    "                if os.path.isdir(item):\n",
    "                    print(f\"   üìÅ {item}\")\n",
    "            raise Exception(\"Please navigate to the correct project directory\")\n",
    "    \n",
    "    # Create data directories\n",
    "    input_dir = os.path.join(base_dir, 'data', 'input')\n",
    "    output_dir = os.path.join(base_dir, 'data', 'output')\n",
    "    \n",
    "    os.makedirs(input_dir, exist_ok=True)\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    print(f\"üìÅ Input directory: {input_dir}\")\n",
    "    print(f\"üìÅ Output directory: {output_dir}\")\n",
    "    \n",
    "    # Verify directories were created\n",
    "    if not os.path.exists(input_dir):\n",
    "        raise Exception(f\"Failed to create input directory: {input_dir}\")\n",
    "    \n",
    "    return input_dir, output_dir\n",
    "\n",
    "# Setup directories\n",
    "try:\n",
    "    input_dir, output_dir = setup_data_directories()\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Directory setup failed: {e}\")\n",
    "    # Fallback to simple relative paths\n",
    "    input_dir = os.path.join('data', 'input')\n",
    "    output_dir = os.path.join('data', 'output')\n",
    "    os.makedirs(input_dir, exist_ok=True)\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    print(f\"üîÑ Using fallback directories:\")\n",
    "    print(f\"   üìÅ Input: {os.path.abspath(input_dir)}\")\n",
    "    print(f\"   üìÅ Output: {os.path.abspath(output_dir)}\")\n",
    "\n",
    "# Initialize parsers\n",
    "try:\n",
    "    csv_parser = CSVParser()\n",
    "    pdf_parser = PDFParser()\n",
    "    print(\"‚úÖ File parsers initialized successfully\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Parser initialization failed: {e}\")\n",
    "    print(\"   Make sure all project modules are properly imported\")\n",
    "    raise\n",
    "\n",
    "# File upload widget (for Jupyter environments)\n",
    "try:\n",
    "    from IPython.display import FileUpload\n",
    "    \n",
    "    print(\"\\nüì§ File Upload Widget Available\")\n",
    "    print(\"You can drag and drop your CSV or PDF files below:\")\n",
    "    \n",
    "    def handle_upload(change):\n",
    "        \"\"\"Handle file upload with enhanced validation\"\"\"\n",
    "        for filename, file_info in change['new'].items():\n",
    "            content = file_info['content']\n",
    "            file_path = os.path.join(input_dir, filename)\n",
    "            \n",
    "            # Save uploaded file\n",
    "            with open(file_path, 'wb') as f:\n",
    "                f.write(content)\n",
    "            \n",
    "            print(f\"‚úì File '{filename}' uploaded successfully!\")\n",
    "            print(f\"   üìç Saved to: {file_path}\")\n",
    "            \n",
    "            # Process and validate the file immediately\n",
    "            process_and_validate_file(file_path)\n",
    "    \n",
    "    # Create upload widget - restrict to CSV and PDF only\n",
    "    uploader = FileUpload(accept='.csv,.pdf', multiple=True)\n",
    "    uploader.observe(handle_upload, names='value')\n",
    "    display(uploader)\n",
    "    \n",
    "except ImportError:\n",
    "    print(\"üí° File upload widget not available. Please use the directory method below.\")\n",
    "\n",
    "print(f\"\\nüìÇ Alternative: Place files in: {os.path.abspath(input_dir)}\")\n",
    "print(\"   Then run the next cell to process them.\")\n",
    "\n",
    "def process_and_validate_file(file_path):\n",
    "    \"\"\"Process and validate a single uploaded file with enhanced checking\"\"\"\n",
    "    filename = os.path.basename(file_path)\n",
    "    print(f\"\\nüîÑ Processing: {filename}\")\n",
    "    print(f\"   üìç Full path: {file_path}\")\n",
    "    \n",
    "    # Check if file exists\n",
    "    if not os.path.exists(file_path):\n",
    "        print(f\"   ‚ùå File not found at path: {file_path}\")\n",
    "        return\n",
    "    \n",
    "    # Check file size\n",
    "    file_size = os.path.getsize(file_path)\n",
    "    if file_size == 0:\n",
    "        print(f\"   ‚ùå File is empty (0 bytes)\")\n",
    "        return\n",
    "    \n",
    "    print(f\"   üìä File size: {file_size:,} bytes\")\n",
    "    \n",
    "    try:\n",
    "        if filename.lower().endswith('.csv'):\n",
    "            # Process CSV with enhanced parser\n",
    "            print(\"   üìä Parsing CSV file...\")\n",
    "            result = csv_parser.parse(file_path)\n",
    "            \n",
    "            df = result['data']\n",
    "            summary = result['summary']\n",
    "            \n",
    "            print(f\"   ‚úÖ CSV processed successfully!\")\n",
    "            print(f\"      ‚Ä¢ Rows: {summary['total_rows']}\")\n",
    "            print(f\"      ‚Ä¢ Date range: {summary['date_range'][0]} to {summary['date_range'][1]}\")\n",
    "            print(f\"      ‚Ä¢ Total amount: ${summary['total_amount']:,.2f}\")\n",
    "            print(f\"      ‚Ä¢ Categories: {len(summary['categories'])}\")\n",
    "            print(f\"      ‚Ä¢ Column mapping: {summary['column_mapping']}\")\n",
    "            print(f\"      ‚Ä¢ Data quality: {summary['data_quality']}/100\")\n",
    "            \n",
    "            # Display data preview\n",
    "            print(\"\\n   üìã Data Preview:\")\n",
    "            display(df.head())\n",
    "            \n",
    "        elif filename.lower().endswith('.pdf'):\n",
    "            # Process PDF with enhanced parser\n",
    "            print(\"   üìÑ Parsing PDF file...\")\n",
    "            result = pdf_parser.parse(file_path)\n",
    "            \n",
    "            df = result['data']\n",
    "            summary = result['summary']\n",
    "            \n",
    "            if summary['total_rows'] == 0:\n",
    "                print(\"   ‚ùå No financial data could be extracted from this PDF.\")\n",
    "                print(\"      üí° Tips for better PDF processing:\")\n",
    "                print(\"         - Use PDFs with clear, readable text\")\n",
    "                print(\"         - Avoid scanned images without OCR\")\n",
    "                print(\"         - Bank statements work better than receipts\")\n",
    "                print(\"         - Try exporting bank data as CSV instead\")\n",
    "                return\n",
    "            \n",
    "            print(f\"   ‚úÖ PDF processed successfully!\")\n",
    "            print(f\"      ‚Ä¢ Rows extracted: {summary['total_rows']}\")\n",
    "            if summary['date_range']:\n",
    "                print(f\"      ‚Ä¢ Date range: {summary['date_range'][0]} to {summary['date_range'][1]}\")\n",
    "            print(f\"      ‚Ä¢ Total amount: ${summary['total_amount']:,.2f}\")\n",
    "            print(f\"      ‚Ä¢ Categories: {len(summary['categories'])}\")\n",
    "            print(f\"      ‚Ä¢ Parsing method: {summary['parsing_method']}\")\n",
    "            print(f\"      ‚Ä¢ Data quality: {summary['data_quality']}/100\")\n",
    "            \n",
    "            # Display data preview\n",
    "            print(\"\\n   üìã Data Preview:\")\n",
    "            display(df.head())\n",
    "            \n",
    "            # PDF-specific feedback\n",
    "            if summary['data_quality'] < 50:\n",
    "                print(\"   ‚ö†Ô∏è  PDF extraction quality is low. Consider:\")\n",
    "                print(\"      - Using a CSV export from your bank instead\")\n",
    "                print(\"      - Ensuring the PDF has selectable text (not scanned)\")\n",
    "                print(\"      - Using a different PDF if available\")\n",
    "        else:\n",
    "            print(\"   ‚ùå Unsupported file format. Please use CSV or PDF files only.\")\n",
    "            return\n",
    "            \n",
    "        # Validate if data is suitable for financial analysis\n",
    "        if 'data_quality' in summary and summary['data_quality'] < 30:\n",
    "            print(\"\\n   üö´ FILE REJECTED: Data quality too poor for analysis\")\n",
    "            print(\"      Please upload a proper financial data file with:\")\n",
    "            print(\"      - Clear date information\")\n",
    "            print(\"      - Numeric amount values\") \n",
    "            print(\"      - At least basic transaction descriptions\")\n",
    "            print(\"      - Minimum 5 transactions\")\n",
    "        else:\n",
    "            print(f\"\\n   ‚úÖ File '{filename}' validated and ready for analysis!\")\n",
    "            \n",
    "    except ValueError as e:\n",
    "        print(f\"   ‚ùå Validation Error: {e}\")\n",
    "        print(\"      Please check your file format and data structure.\")\n",
    "    except Exception as e:\n",
    "        print(f\"   ‚ùå Processing Error: {e}\")\n",
    "        print(\"      Please try a different file or check file integrity.\")\n",
    "\n",
    "# Debug: Check current directory contents\n",
    "print(f\"\\nüîç Debugging - Directory Contents:\")\n",
    "print(f\"   üìÇ Current directory ({current_dir}):\")\n",
    "for item in os.listdir(current_dir):\n",
    "    if os.path.isdir(os.path.join(current_dir, item)):\n",
    "        print(f\"      üìÅ {item}/\")\n",
    "    else:\n",
    "        print(f\"      üìÑ {item}\")\n",
    "\n",
    "print(f\"\\n   üìÇ Input directory ({input_dir}):\")\n",
    "if os.path.exists(input_dir):\n",
    "    input_contents = os.listdir(input_dir)\n",
    "    if input_contents:\n",
    "        for item in input_contents:\n",
    "            print(f\"      üìÑ {item}\")\n",
    "    else:\n",
    "        print(\"      (empty)\")\n",
    "else:\n",
    "    print(\"      ‚ùå Directory does not exist\")\n",
    "\n",
    "# Check for existing files in input directory\n",
    "try:\n",
    "    existing_files = [f for f in os.listdir(input_dir) \n",
    "                     if f.lower().endswith(('.csv', '.pdf'))]\n",
    "\n",
    "    if existing_files:\n",
    "        print(f\"\\nüìã Found {len(existing_files)} existing file(s):\")\n",
    "        for file in existing_files:\n",
    "            print(f\"   ‚Ä¢ {file}\")\n",
    "            file_path = os.path.join(input_dir, file)\n",
    "            process_and_validate_file(file_path)\n",
    "    else:\n",
    "        print(\"\\nüí° No files found in input directory.\")\n",
    "        print(\"   üìù For proper analysis, your files should contain:\")\n",
    "        print(\"      ‚Ä¢ CSV: columns for date, amount, category/description\")\n",
    "        print(\"      ‚Ä¢ PDF: bank statements or transaction reports\")\n",
    "        print(\"   üìÅ Upload files above or add them to the directory and rerun this cell.\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"\\n‚ùå Error checking input directory: {e}\")\n",
    "    print(f\"   Directory path: {input_dir}\")\n",
    "    print(\"   Please verify the directory exists and has proper permissions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1084aeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================================\n",
    "# 4. DATA PROCESSING AND ANALYSIS\n",
    "# ========================================\n",
    "\n",
    "# Process all files in the input directory\n",
    "input_files = [f for f in os.listdir(input_dir) if f.endswith(('.csv', '.pdf'))]\n",
    "processed_data = {}\n",
    "financial_summaries = {}\n",
    "\n",
    "if not input_files:\n",
    "    print(\"‚ùå No data files found. Please upload files in the previous cell.\")\n",
    "    processed_data = None\n",
    "else:\n",
    "    print(f\"üîÑ Processing {len(input_files)} file(s)...\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    for filename in input_files:\n",
    "        file_path = os.path.join(input_dir, filename)\n",
    "        print(f\"\\nüìÑ Processing: {filename}\")\n",
    "        \n",
    "        try:\n",
    "            # Load file using the file_loader utility\n",
    "            file_data = file_loader.load_file(file_path)\n",
    "            processed_data[filename] = file_data\n",
    "            \n",
    "            # Extract the DataFrame\n",
    "            df = file_data['data']\n",
    "            \n",
    "            # Basic statistics\n",
    "            print(f\"   ‚úì Loaded {len(df)} transactions\")\n",
    "            print(f\"   ‚úì Date range: {df['date'].min()} to {df['date'].max()}\")\n",
    "            print(f\"   ‚úì Total amount: ${df['amount'].sum():.2f}\")\n",
    "            print(f\"   ‚úì Categories: {', '.join(df['category'].unique())}\")\n",
    "            \n",
    "            # Store summary for later use\n",
    "            financial_summaries[filename] = {\n",
    "                'total_amount': df['amount'].sum(),\n",
    "                'transaction_count': len(df),\n",
    "                'categories': df['category'].unique().tolist(),\n",
    "                'date_range': (df['date'].min(), df['date'].max()),\n",
    "                'avg_transaction': df['amount'].mean()\n",
    "            }\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"   ‚ùå Error processing {filename}: {e}\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 50)\n",
    "    print(\"‚úì Data processing complete!\")\n",
    "    \n",
    "    # Show overall summary\n",
    "    if processed_data:\n",
    "        total_transactions = sum(s['transaction_count'] for s in financial_summaries.values())\n",
    "        total_amount = sum(s['total_amount'] for s in financial_summaries.values())\n",
    "        all_categories = set()\n",
    "        for s in financial_summaries.values():\n",
    "            all_categories.update(s['categories'])\n",
    "        \n",
    "        print(f\"\\nüìä OVERALL SUMMARY:\")\n",
    "        print(f\"   ‚Ä¢ Total files processed: {len(processed_data)}\")\n",
    "        print(f\"   ‚Ä¢ Total transactions: {total_transactions}\")\n",
    "        print(f\"   ‚Ä¢ Total amount: ${total_amount:.2f}\")\n",
    "        print(f\"   ‚Ä¢ Unique categories: {len(all_categories)}\")\n",
    "        print(f\"   ‚Ä¢ Categories: {', '.join(sorted(all_categories))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a9c11bd",
   "metadata": {},
   "source": [
    "# 5. Data Visualization\n",
    "\n",
    "Generate comprehensive visualizations of your financial data:\n",
    "\n",
    "- **Monthly Spending Trends**: Track how your spending changes over time\n",
    "- **Category Breakdown**: See where your money goes (pie charts and bar charts)\n",
    "- **Daily Spending Patterns**: Identify spending habits by day of week/month\n",
    "- **Budget Analysis**: Compare actual spending vs recommended percentages\n",
    "- **Savings Analysis**: Track your saving patterns and goals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9de13312",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================================\n",
    "# 5. COMPREHENSIVE DATA VISUALIZATION  \n",
    "# ========================================\n",
    "\n",
    "if not processed_data:\n",
    "    print(\"‚ùå No data to visualize. Please process data files first.\")\n",
    "else:\n",
    "    print(\"üìä Generating comprehensive visualizations...\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    # Combine all dataframes for comprehensive analysis\n",
    "    all_dataframes = []\n",
    "    for filename, file_data in processed_data.items():\n",
    "        df = file_data['data'].copy()\n",
    "        df['source_file'] = filename  # Track which file data came from\n",
    "        all_dataframes.append(df)\n",
    "    \n",
    "    # Create master dataframe\n",
    "    master_df = pd.concat(all_dataframes, ignore_index=True)\n",
    "    master_df['date'] = pd.to_datetime(master_df['date'])\n",
    "    \n",
    "    print(f\"üìà Creating AI-powered visualizations for {len(master_df)} total transactions...\")\n",
    "    \n",
    "    # Initialize enhanced chart generator\n",
    "    enhanced_chart_gen = ChartGenerator()\n",
    "    \n",
    "    # Analyze data characteristics to determine best visualizations\n",
    "    data_characteristics = {\n",
    "        'num_transactions': len(master_df),\n",
    "        'date_span_days': (master_df['date'].max() - master_df['date'].min()).days,\n",
    "        'num_categories': master_df['category'].nunique(),\n",
    "        'amount_range': master_df['amount'].max() - master_df['amount'].min(),\n",
    "        'has_monthly_data': (master_df['date'].max() - master_df['date'].min()).days >= 30\n",
    "    }\n",
    "    \n",
    "    print(f\"   üìä Data analysis complete:\")\n",
    "    print(f\"      ‚Ä¢ Time span: {data_characteristics['date_span_days']} days\")\n",
    "    print(f\"      ‚Ä¢ Categories: {data_characteristics['num_categories']}\")\n",
    "    print(f\"      ‚Ä¢ Amount range: ${data_characteristics['amount_range']:,.2f}\")\n",
    "    \n",
    "    # Create comprehensive dashboard\n",
    "    try:\n",
    "        all_charts = enhanced_chart_gen.create_comprehensive_dashboard(master_df)\n",
    "        \n",
    "        # Display charts based on data characteristics\n",
    "        charts_to_show = []\n",
    "        \n",
    "        # Always show overview charts\n",
    "        essential_charts = ['monthly_trend', 'category_pie', 'top_categories']\n",
    "        charts_to_show.extend(essential_charts)\n",
    "        \n",
    "        # Add time-based charts if we have sufficient temporal data\n",
    "        if data_characteristics['has_monthly_data']:\n",
    "            charts_to_show.extend(['monthly_heatmap', 'cumulative_spending'])\n",
    "        \n",
    "        # Add pattern analysis if we have enough categories\n",
    "        if data_characteristics['num_categories'] >= 3:\n",
    "            charts_to_show.extend(['weekday_analysis', 'category_timeline'])\n",
    "        \n",
    "        # Add distribution analysis if we have enough transactions\n",
    "        if data_characteristics['num_transactions'] >= 20:\n",
    "            charts_to_show.extend(['amount_histogram', 'daily_distribution'])\n",
    "        \n",
    "        # Display selected charts\n",
    "        print(f\"\\nüìà Displaying {len(charts_to_show)} optimized visualizations:\")\n",
    "        \n",
    "        for chart_name in charts_to_show:\n",
    "            if chart_name in all_charts:\n",
    "                print(f\"\\nüìä {chart_name.replace('_', ' ').title()}\")\n",
    "                display(all_charts[chart_name])\n",
    "        \n",
    "        # Save all charts\n",
    "        try:\n",
    "            saved_files = enhanced_chart_gen.save_charts(\n",
    "                all_charts, \n",
    "                output_dir, \n",
    "                formats=['html']\n",
    "            )\n",
    "            print(f\"\\nüíæ Charts saved to: {output_dir}\")\n",
    "            print(f\"   üìÅ {len(saved_files)} files created\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"‚ö†Ô∏è  Could not save charts: {e}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error with enhanced charts, falling back to basic visualizations: {e}\")\n",
    "        \n",
    "        # Fallback to basic visualizations\n",
    "        print(\"\\nüîÑ Creating basic visualizations...\")\n",
    "        \n",
    "        # 1. MONTHLY SPENDING TREND\n",
    "        print(\"\\n1Ô∏è‚É£ Monthly Spending Trend\")\n",
    "        monthly_spending = master_df.groupby(master_df['date'].dt.to_period('M'))['amount'].sum()\n",
    "        \n",
    "        fig_monthly = go.Figure()\n",
    "        fig_monthly.add_trace(go.Scatter(\n",
    "            x=[str(period) for period in monthly_spending.index],\n",
    "            y=monthly_spending.values,\n",
    "            mode='lines+markers',\n",
    "            name='Monthly Spending',\n",
    "            line=dict(width=3),\n",
    "            marker=dict(size=8)\n",
    "        ))\n",
    "        \n",
    "        fig_monthly.update_layout(\n",
    "            title='üìà Monthly Spending Trend',\n",
    "            xaxis_title='Month',\n",
    "            yaxis_title='Amount ($)',\n",
    "            height=400,\n",
    "            template='plotly_white'\n",
    "        )\n",
    "        display(fig_monthly)\n",
    "        \n",
    "        # 2. CATEGORY BREAKDOWN (PIE CHART)\n",
    "        print(\"\\n2Ô∏è‚É£ Spending by Category\")\n",
    "        category_totals = master_df.groupby('category')['amount'].sum().sort_values(ascending=False)\n",
    "        \n",
    "        fig_pie = go.Figure(data=[go.Pie(\n",
    "            labels=category_totals.index,\n",
    "            values=category_totals.values,\n",
    "            hole=0.3,\n",
    "            textinfo='label+percent',\n",
    "            textposition='outside'\n",
    "        )])\n",
    "        \n",
    "        fig_pie.update_layout(\n",
    "            title='ü•ß Spending Breakdown by Category',\n",
    "            height=500,\n",
    "            template='plotly_white'\n",
    "        )\n",
    "        display(fig_pie)\n",
    "        \n",
    "        # 3. TOP SPENDING CATEGORIES (BAR CHART)\n",
    "        print(\"\\n3Ô∏è‚É£ Top Spending Categories\")\n",
    "        top_categories = category_totals.head(10)\n",
    "        \n",
    "        fig_bar = go.Figure(data=[go.Bar(\n",
    "            x=top_categories.values,\n",
    "            y=top_categories.index,\n",
    "            orientation='h',\n",
    "            marker_color='lightblue'\n",
    "        )])\n",
    "        \n",
    "        fig_bar.update_layout(\n",
    "            title='üìä Top 10 Spending Categories',\n",
    "            xaxis_title='Amount ($)',\n",
    "            yaxis_title='Category',\n",
    "            height=400,\n",
    "            template='plotly_white'\n",
    "        )\n",
    "        display(fig_bar)\n",
    "    \n",
    "    # AI-powered insights based on visualizations\n",
    "    print(\"\\n\" + \"=\" * 50)\n",
    "    print(\"ü§ñ AI INSIGHTS FROM VISUALIZATIONS:\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    # Generate insights based on the data\n",
    "    top_category = master_df.groupby('category')['amount'].sum().idxmax()\n",
    "    top_amount = master_df.groupby('category')['amount'].sum().max()\n",
    "    total_spending = master_df['amount'].sum()\n",
    "    avg_transaction = master_df['amount'].mean()\n",
    "    \n",
    "    insights = []\n",
    "    insights.append(f\"üí∞ Your highest spending category is '{top_category}' (${top_amount:,.2f})\")\n",
    "    insights.append(f\"\udcca This represents {(top_amount/total_spending)*100:.1f}% of your total spending\")\n",
    "    insights.append(f\"üí≥ Your average transaction amount is ${avg_transaction:.2f}\")\n",
    "    \n",
    "    if data_characteristics['has_monthly_data']:\n",
    "        monthly_avg = master_df.groupby(master_df['date'].dt.to_period('M'))['amount'].sum().mean()\n",
    "        insights.append(f\"üìÖ Your average monthly spending is ${monthly_avg:,.2f}\")\n",
    "    \n",
    "    # Category diversity insight\n",
    "    if data_characteristics['num_categories'] <= 3:\n",
    "        insights.append(\"‚ö†Ô∏è  Consider tracking more specific expense categories for better budgeting\")\n",
    "    elif data_characteristics['num_categories'] >= 10:\n",
    "        insights.append(\"‚úÖ Good category diversity - this helps with detailed budget analysis\")\n",
    "    \n",
    "    for insight in insights:\n",
    "        print(f\"   {insight}\")\n",
    "    \n",
    "    print(\"\\n‚úÖ All visualizations generated successfully!\")\n",
    "    print(\"üí° Use the AI chat interface below to get personalized insights about your spending patterns.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fe29ddc",
   "metadata": {},
   "source": [
    "# 6. Multi-Agent Financial Analysis System\n",
    "\n",
    "Your intelligent financial advisor team is ready! This system uses multiple AI agents working collaboratively:\n",
    "\n",
    "## \udd04 **Multi-Agent Workflow**\n",
    "- **Planner Agent (GPT-2)**: Analyzes data and creates analysis plans\n",
    "- **Executor Agent (DistilBERT)**: Executes the planned analysis tasks\n",
    "- **Reviewer Agent (GPT-2)**: Verifies results and suggests optimizations\n",
    "\n",
    "## üí° **Collaborative Analysis Features**\n",
    "- **Task Planning**: AI creates structured analysis plans\n",
    "- **Cross-Validation**: Multiple agents verify each other's work\n",
    "- **Optimization Suggestions**: Continuous improvement of analysis\n",
    "- **Role Switching**: Agents can switch roles for different perspectives\n",
    "\n",
    "## üìä **Analysis Workflow**\n",
    "1. **Plan Phase**: Agent analyzes your data and creates analysis strategy\n",
    "2. **Execute Phase**: Different agent performs the planned analysis\n",
    "3. **Review Phase**: Third agent validates and optimizes results\n",
    "4. **Interactive Chat**: Discuss findings with the collaborative team\n",
    "\n",
    "## üéØ **Collaborative Commands**\n",
    "- `plan analysis` - Create structured analysis plan\n",
    "- `execute plan` - Run the planned analysis\n",
    "- `review results` - Validate and optimize findings\n",
    "- `switch roles` - Change agent responsibilities\n",
    "- `team discussion` - Multi-agent conversation mode\n",
    "\n",
    "**Type 'help' for commands | 'quit' to exit | 'team' for collaborative mode**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19ef0fc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================================\n",
    "# 6. MULTI-AGENT COLLABORATIVE ANALYSIS SYSTEM\n",
    "# ========================================\n",
    "\n",
    "class MultiAgentAnalysisSystem:\n",
    "    \"\"\"Multi-agent system for collaborative financial analysis\"\"\"\n",
    "    \n",
    "    def __init__(self, agents_dict, financial_data):\n",
    "        self.agents = agents_dict\n",
    "        self.financial_data = financial_data\n",
    "        self.analysis_history = []\n",
    "        self.current_plan = None\n",
    "        self.execution_results = None\n",
    "        \n",
    "        # Define agent roles\n",
    "        self.roles = {\n",
    "            'planner': 'gpt2_agent',      # Plans analysis strategy\n",
    "            'executor': 'distilbert_agent', # Executes planned tasks\n",
    "            'reviewer': 'gpt2_agent'       # Reviews and optimizes results\n",
    "        }\n",
    "        \n",
    "        self.collaboration_log = []\n",
    "    \n",
    "    def create_analysis_plan(self, user_request):\n",
    "        \"\"\"Planner agent creates structured analysis plan\"\"\"\n",
    "        planner = self.agents[self.roles['planner']]\n",
    "        \n",
    "        planning_prompt = f\"\"\"\n",
    "        As a Financial Analysis Planner, create a detailed analysis plan for this request: \"{user_request}\"\n",
    "        \n",
    "        Available data summary:\n",
    "        - Total transactions: {len(self.financial_data) if self.financial_data is not None else 0}\n",
    "        - Categories: {list(self.financial_data['category'].unique()) if self.financial_data is not None else 'None'}\n",
    "        \n",
    "        Create a step-by-step analysis plan with:\n",
    "        1. Data requirements\n",
    "        2. Analysis steps\n",
    "        3. Expected outputs\n",
    "        4. Success criteria\n",
    "        \n",
    "        Format as a clear, actionable plan.\n",
    "        \"\"\"\n",
    "        \n",
    "        plan = planner.run(planning_prompt)\n",
    "        self.current_plan = {\n",
    "            'request': user_request,\n",
    "            'plan': plan,\n",
    "            'created_by': 'planner',\n",
    "            'timestamp': pd.Timestamp.now()\n",
    "        }\n",
    "        \n",
    "        self.collaboration_log.append(f\"üìã Planner created analysis plan for: {user_request}\")\n",
    "        return plan\n",
    "    \n",
    "    def execute_analysis_plan(self):\n",
    "        \"\"\"Executor agent performs the planned analysis\"\"\"\n",
    "        if not self.current_plan:\n",
    "            return \"No analysis plan available. Please create a plan first.\"\n",
    "        \n",
    "        executor = self.agents[self.roles['executor']]\n",
    "        \n",
    "        execution_prompt = f\"\"\"\n",
    "        As a Financial Analysis Executor, perform this analysis plan:\n",
    "        \n",
    "        Plan: {self.current_plan['plan']}\n",
    "        \n",
    "        Execute each step and provide detailed results with specific numbers and insights.\n",
    "        Focus on actionable findings and concrete data points.\n",
    "        \"\"\"\n",
    "        \n",
    "        results = executor.run(execution_prompt)\n",
    "        self.execution_results = {\n",
    "            'results': results,\n",
    "            'executed_by': 'executor',\n",
    "            'timestamp': pd.Timestamp.now(),\n",
    "            'original_plan': self.current_plan\n",
    "        }\n",
    "        \n",
    "        self.collaboration_log.append(f\"‚ö° Executor completed analysis execution\")\n",
    "        return results\n",
    "    \n",
    "    def review_and_optimize(self):\n",
    "        \"\"\"Reviewer agent validates and optimizes the results\"\"\"\n",
    "        if not self.execution_results:\n",
    "            return \"No execution results available. Please execute an analysis first.\"\n",
    "        \n",
    "        reviewer = self.agents[self.roles['reviewer']]\n",
    "        \n",
    "        review_prompt = f\"\"\"\n",
    "        As a Financial Analysis Reviewer, evaluate these analysis results:\n",
    "        \n",
    "        Original Plan: {self.current_plan['plan']}\n",
    "        Execution Results: {self.execution_results['results']}\n",
    "        \n",
    "        Provide:\n",
    "        1. Quality assessment of the analysis\n",
    "        2. Accuracy verification\n",
    "        3. Missing elements identification\n",
    "        4. Optimization suggestions\n",
    "        5. Final recommendations\n",
    "        \n",
    "        Be thorough and constructive in your review.\n",
    "        \"\"\"\n",
    "        \n",
    "        review = reviewer.run(review_prompt)\n",
    "        \n",
    "        optimized_result = {\n",
    "            'review': review,\n",
    "            'reviewed_by': 'reviewer',\n",
    "            'timestamp': pd.Timestamp.now(),\n",
    "            'original_results': self.execution_results\n",
    "        }\n",
    "        \n",
    "        # Store complete analysis cycle\n",
    "        self.analysis_history.append({\n",
    "            'plan': self.current_plan,\n",
    "            'execution': self.execution_results,\n",
    "            'review': optimized_result\n",
    "        })\n",
    "        \n",
    "        self.collaboration_log.append(f\"üîç Reviewer completed analysis review and optimization\")\n",
    "        return review\n",
    "    \n",
    "    def switch_roles(self, role1, role2):\n",
    "        \"\"\"Switch agent roles for different perspectives\"\"\"\n",
    "        if role1 in self.roles and role2 in self.roles:\n",
    "            # Swap the agents\n",
    "            agent1, agent2 = self.roles[role1], self.roles[role2]\n",
    "            self.roles[role1], self.roles[role2] = agent2, agent1\n",
    "            \n",
    "            self.collaboration_log.append(f\"üîÑ Switched roles: {role1} ‚Üî {role2}\")\n",
    "            return f\"Roles switched: {role1} ‚Üî {role2}\"\n",
    "        else:\n",
    "            return \"Invalid roles. Available roles: planner, executor, reviewer\"\n",
    "    \n",
    "    def team_discussion(self, topic):\n",
    "        \"\"\"Multi-agent discussion on a topic\"\"\"\n",
    "        discussions = {}\n",
    "        \n",
    "        # Each agent provides their perspective\n",
    "        for role, agent_name in self.roles.items():\n",
    "            agent = self.agents[agent_name]\n",
    "            \n",
    "            discussion_prompt = f\"\"\"\n",
    "            As a {role} in our financial analysis team, provide your perspective on: \"{topic}\"\n",
    "            \n",
    "            Consider your role's expertise and provide insights that complement the other team members.\n",
    "            Keep your response focused and valuable to the collaborative analysis.\n",
    "            \"\"\"\n",
    "            \n",
    "            response = agent.run(discussion_prompt)\n",
    "            discussions[role] = response\n",
    "        \n",
    "        # Synthesize the discussion\n",
    "        synthesis_prompt = f\"\"\"\n",
    "        Synthesize these team perspectives on \"{topic}\":\n",
    "        \n",
    "        Planner's view: {discussions.get('planner', 'Not available')}\n",
    "        Executor's view: {discussions.get('executor', 'Not available')} \n",
    "        Reviewer's view: {discussions.get('reviewer', 'Not available')}\n",
    "        \n",
    "        Provide a balanced synthesis highlighting key insights and consensus points.\n",
    "        \"\"\"\n",
    "        \n",
    "        synthesis = self.agents[self.roles['planner']].run(synthesis_prompt)\n",
    "        \n",
    "        self.collaboration_log.append(f\"üí¨ Team discussion completed on: {topic}\")\n",
    "        \n",
    "        return {\n",
    "            'individual_perspectives': discussions,\n",
    "            'synthesis': synthesis\n",
    "        }\n",
    "    \n",
    "    def get_collaboration_status(self):\n",
    "        \"\"\"Get current status of collaborative analysis\"\"\"\n",
    "        status = {\n",
    "            'current_roles': self.roles,\n",
    "            'has_plan': self.current_plan is not None,\n",
    "            'has_execution': self.execution_results is not None,\n",
    "            'completed_analyses': len(self.analysis_history),\n",
    "            'recent_activity': self.collaboration_log[-5:] if self.collaboration_log else []\n",
    "        }\n",
    "        return status\n",
    "\n",
    "def collaborative_chat_interface():\n",
    "    \"\"\"Enhanced chat interface with multi-agent collaboration\"\"\"\n",
    "    \n",
    "    if not processed_data:\n",
    "        print(\"‚ùå No financial data loaded. Please process data files first.\")\n",
    "        return\n",
    "    \n",
    "    # Initialize multi-agent system\n",
    "    agents_dict = {}\n",
    "    if gpt2_model and gpt2_agent:\n",
    "        agents_dict['gpt2_agent'] = gpt2_agent\n",
    "    if distilbert_model and distilbert_agent:\n",
    "        agents_dict['distilbert_agent'] = distilbert_agent\n",
    "    \n",
    "    if len(agents_dict) < 2:\n",
    "        print(\"‚ùå Need at least 2 AI models for collaborative analysis.\")\n",
    "        return\n",
    "    \n",
    "    # Combine data for analysis\n",
    "    combined_df = pd.concat([file_data['data'] for file_data in processed_data.values()], \n",
    "                           ignore_index=True)\n",
    "    \n",
    "    # Initialize multi-agent system\n",
    "    multi_agent_system = MultiAgentAnalysisSystem(agents_dict, combined_df)\n",
    "    \n",
    "    print(\"ü§ñ Multi-Agent Financial Analysis Team Ready!\")\n",
    "    print(\"=\" * 60)\n",
    "    print(\"üë• Team Members:\")\n",
    "    for role, agent in multi_agent_system.roles.items():\n",
    "        model_name = \"GPT-2\" if \"gpt2\" in agent else \"DistilBERT\"\n",
    "        print(f\"   {role.title()}: {model_name}\")\n",
    "    \n",
    "    print(\"\\nüí° The team can work together on complex financial analysis!\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # Prepare financial context\n",
    "    total_amount = sum(s['total_amount'] for s in financial_summaries.values())\n",
    "    total_transactions = sum(s['transaction_count'] for s in financial_summaries.values())\n",
    "    \n",
    "    print(\"\\n\" + \"-\" * 60)\n",
    "    print(\"Commands: 'plan' | 'execute' | 'review' | 'switch' | 'team' | 'status' | 'quit'\")\n",
    "    print(\"-\" * 60)\n",
    "    \n",
    "    while True:\n",
    "        user_input = input(\"\\nüí¨ You: \").strip()\n",
    "        \n",
    "        if user_input.lower() == 'quit':\n",
    "            print(\"\\nüëã Thank you for using the Multi-Agent Financial Analysis System!\")\n",
    "            break\n",
    "            \n",
    "        elif user_input.lower().startswith('plan'):\n",
    "            request = user_input[4:].strip() or \"comprehensive financial analysis\"\n",
    "            print(f\"\\nüìã Creating analysis plan for: {request}\")\n",
    "            print(\"-\" * 40)\n",
    "            plan = multi_agent_system.create_analysis_plan(request)\n",
    "            print(f\"ü§ñ Planner's Analysis Plan:\\n{plan}\")\n",
    "            \n",
    "        elif user_input.lower() == 'execute':\n",
    "            print(\"\\n‚ö° Executing analysis plan...\")\n",
    "            print(\"-\" * 30)\n",
    "            results = multi_agent_system.execute_analysis_plan()\n",
    "            print(f\"ü§ñ Executor's Results:\\n{results}\")\n",
    "            \n",
    "        elif user_input.lower() == 'review':\n",
    "            print(\"\\nüîç Reviewing and optimizing results...\")\n",
    "            print(\"-\" * 35)\n",
    "            review = multi_agent_system.review_and_optimize()\n",
    "            print(f\"ü§ñ Reviewer's Assessment:\\n{review}\")\n",
    "            \n",
    "        elif user_input.lower().startswith('switch'):\n",
    "            # Parse switch command: \"switch planner executor\"\n",
    "            parts = user_input.split()\n",
    "            if len(parts) >= 3:\n",
    "                result = multi_agent_system.switch_roles(parts[1], parts[2])\n",
    "                print(f\"\\nüîÑ {result}\")\n",
    "                print(\"Updated roles:\")\n",
    "                for role, agent in multi_agent_system.roles.items():\n",
    "                    model_name = \"GPT-2\" if \"gpt2\" in agent else \"DistilBERT\"\n",
    "                    print(f\"   {role.title()}: {model_name}\")\n",
    "            else:\n",
    "                print(\"\\nUsage: switch <role1> <role2>\")\n",
    "                print(\"Available roles: planner, executor, reviewer\")\n",
    "                \n",
    "        elif user_input.lower().startswith('team'):\n",
    "            topic = user_input[4:].strip() or \"overall financial health\"\n",
    "            print(f\"\\n\udcac Team discussion on: {topic}\")\n",
    "            print(\"-\" * 40)\n",
    "            discussion = multi_agent_system.team_discussion(topic)\n",
    "            \n",
    "            print(\"Individual Perspectives:\")\n",
    "            for role, perspective in discussion['individual_perspectives'].items():\n",
    "                print(f\"\\nü§ñ {role.title()}: {perspective}\")\n",
    "            \n",
    "            print(f\"\\n\udfaf Team Synthesis:\\n{discussion['synthesis']}\")\n",
    "            \n",
    "        elif user_input.lower() == 'status':\n",
    "            status = multi_agent_system.get_collaboration_status()\n",
    "            print(\"\\nüìä Collaboration Status:\")\n",
    "            print(f\"   Current Roles: {status['current_roles']}\")\n",
    "            print(f\"   Has Plan: {'‚úÖ' if status['has_plan'] else '‚ùå'}\")\n",
    "            print(f\"   Has Execution: {'‚úÖ' if status['has_execution'] else '‚ùå'}\")\n",
    "            print(f\"   Completed Analyses: {status['completed_analyses']}\")\n",
    "            print(\"\\n Recent Activity:\")\n",
    "            for activity in status['recent_activity']:\n",
    "                print(f\"   ‚Ä¢ {activity}\")\n",
    "                \n",
    "        elif user_input.lower() == 'help':\n",
    "            print(\"\"\"\n",
    "\udd98 MULTI-AGENT COLLABORATION COMMANDS:\n",
    "\n",
    "üìã Analysis Workflow:\n",
    "  ‚Ä¢ 'plan [description]' - Create analysis plan\n",
    "  ‚Ä¢ 'execute' - Execute the current plan\n",
    "  ‚Ä¢ 'review' - Review and optimize results\n",
    "\n",
    "üîÑ Team Management:\n",
    "  ‚Ä¢ 'switch <role1> <role2>' - Switch agent roles\n",
    "  ‚Ä¢ 'team [topic]' - Multi-agent discussion\n",
    "  ‚Ä¢ 'status' - View collaboration status\n",
    "\n",
    "üí¨ Regular Chat:\n",
    "  ‚Ä¢ Ask any financial question for collaborative response\n",
    "  ‚Ä¢ 'quit' - Exit the system\n",
    "  ‚Ä¢ 'help' - Show this help\n",
    "\n",
    "üéØ Example Workflow:\n",
    "  1. plan spending optimization\n",
    "  2. execute\n",
    "  3. review\n",
    "  4. team budget recommendations\n",
    "            \"\"\")\n",
    "            \n",
    "        elif user_input.lower() == '':\n",
    "            continue\n",
    "        \n",
    "        else:\n",
    "            # Regular collaborative analysis\n",
    "            print(f\"\\nü§ñ Collaborative Analysis:\")\n",
    "            print(\"-\" * 30)\n",
    "            \n",
    "            # Get perspective from current planner\n",
    "            planner = multi_agent_system.agents[multi_agent_system.roles['planner']]\n",
    "            planner_response = planner.run(f\"Financial question: {user_input}\")\n",
    "            \n",
    "            # Get perspective from current executor\n",
    "            executor = multi_agent_system.agents[multi_agent_system.roles['executor']]\n",
    "            executor_response = executor.run(f\"Analyze and provide data: {user_input}\")\n",
    "            \n",
    "            print(f\"üß† Planner's Insight: {planner_response}\")\n",
    "            print(f\"\\n‚ö° Executor's Analysis: {executor_response}\")\n",
    "            \n",
    "            multi_agent_system.collaboration_log.append(f\"üí¨ Collaborative response to: {user_input}\")\n",
    "\n",
    "# Start the collaborative system\n",
    "print(\"üöÄ Starting Multi-Agent Collaborative Analysis System...\")\n",
    "collaborative_chat_interface()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d48a80a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================================\n",
    "# ALTERNATIVE: SINGLE-AGENT INTERFACE\n",
    "# ========================================\n",
    "# Uncomment this section if you prefer a simpler single-agent interface\n",
    "\n",
    "\"\"\"\n",
    "def simple_chat_interface():\n",
    "    '''Simple single-agent chat interface'''\n",
    "    \n",
    "    if not processed_data:\n",
    "        print(\"‚ùå No financial data loaded. Please process data files first.\")\n",
    "        return\n",
    "    \n",
    "    # Choose primary agent\n",
    "    current_agent = gpt2_agent if gpt2_agent else distilbert_agent\n",
    "    current_model = \"GPT-2\" if gpt2_agent else \"DistilBERT\"\n",
    "    \n",
    "    if not current_agent:\n",
    "        print(\"‚ùå No AI models available.\")\n",
    "        return\n",
    "    \n",
    "    print(f\"ü§ñ Simple Financial Assistant ({current_model}) Ready!\")\n",
    "    print(\"=\" * 50)\n",
    "    print(\"Type 'quit' to exit, 'help' for commands\")\n",
    "    \n",
    "    while True:\n",
    "        user_input = input(\"\\nüí¨ You: \").strip()\n",
    "        \n",
    "        if user_input.lower() == 'quit':\n",
    "            print(\"\\nüëã Goodbye!\")\n",
    "            break\n",
    "        elif user_input.lower() == 'help':\n",
    "            print(\"Ask me anything about your financial data!\")\n",
    "        else:\n",
    "            response = current_agent.run(user_input)\n",
    "            print(f\"\\nü§ñ {current_model}: {response}\")\n",
    "\n",
    "# Uncomment the line below to use simple interface instead:\n",
    "# simple_chat_interface()\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c9281b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================================\n",
    "# RAG-BASED BUDGET ANALYSIS & RECOMMENDATIONS\n",
    "# ========================================\n",
    "\n",
    "if processed_data:\n",
    "    print(\"üí° Generating Budget Analysis & Recommendations from Your Data...\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # Ask for monthly income without default\n",
    "    while True:\n",
    "        try:\n",
    "            income_input = input(\"üí∞ Enter your monthly income: $\").strip()\n",
    "            if income_input:\n",
    "                monthly_income = float(income_input)\n",
    "                break\n",
    "            else:\n",
    "                print(\"‚ö†Ô∏è Please enter a valid monthly income amount.\")\n",
    "        except ValueError:\n",
    "            print(\"‚ö†Ô∏è Please enter a valid number.\")\n",
    "    \n",
    "    # Combine all uploaded data for analysis\n",
    "    all_dataframes = []\n",
    "    for filename, file_data in processed_data.items():\n",
    "        print(f\"üìÑ Including data from: {filename}\")\n",
    "        all_dataframes.append(file_data['data'])\n",
    "    \n",
    "    master_df = pd.concat(all_dataframes, ignore_index=True)\n",
    "    print(f\"üìä Analyzing {len(master_df)} transactions from uploaded files...\")\n",
    "    \n",
    "    # Calculate budget analysis from user's actual data\n",
    "    budget_analysis = budget_calc.calculate_budget(monthly_income, master_df)\n",
    "    \n",
    "    print(f\"\\nüìä BUDGET ANALYSIS for ${monthly_income:,.2f} monthly income:\")\n",
    "    print(\"-\" * 40)\n",
    "    \n",
    "    # Summary\n",
    "    summary = budget_analysis['summary']\n",
    "    print(f\"üí∞ Total Income:     ${summary['total_income']:,.2f}\")\n",
    "    print(f\"üí∏ Total Expenses:   ${summary['total_expenses']:,.2f}\")\n",
    "    print(f\"üíµ Remaining Budget: ${summary['remaining_budget']:,.2f}\")\n",
    "    print(f\"üíæ Savings Rate:     {summary['savings_rate']:.1f}%\")\n",
    "    \n",
    "    # Category breakdown from uploaded data\n",
    "    print(f\"\\nüè∑Ô∏è  SPENDING BY CATEGORY (from uploaded data):\")\n",
    "    print(\"-\" * 30)\n",
    "    for category, amount in budget_analysis['category_breakdown'].items():\n",
    "        percentage = budget_analysis['category_percentages'][category]\n",
    "        print(f\"{category:15} ${amount:8,.2f} ({percentage:5.1f}%)\")\n",
    "    \n",
    "    # Data-driven recommendations\n",
    "    print(f\"\\nüí° RECOMMENDATIONS (based on your data patterns):\")\n",
    "    print(\"-\" * 20)\n",
    "    for i, rec in enumerate(budget_analysis['recommendations'], 1):\n",
    "        print(f\"{i}. {rec}\")\n",
    "    \n",
    "    # Trend analysis from user data\n",
    "    print(f\"\\nüìà TREND ANALYSIS (from uploaded data):\")\n",
    "    print(\"-\" * 18)\n",
    "    trend_analysis = trend_analyzer.analyze_trends(master_df)\n",
    "    print(trend_analysis['summary'])\n",
    "    \n",
    "    # Save analysis to file\n",
    "    analysis_file = os.path.join(output_dir, 'budget_analysis.txt')\n",
    "    with open(analysis_file, 'w') as f:\n",
    "        f.write(f\"Budget Analysis Report (RAG-based)\\n\")\n",
    "        f.write(f\"Generated: {pd.Timestamp.now()}\\n\")\n",
    "        f.write(f\"Data Sources: {', '.join(processed_data.keys())}\\n\")\n",
    "        f.write(f\"Total Transactions Analyzed: {len(master_df)}\\n\")\n",
    "        f.write(f\"Monthly Income: ${monthly_income:,.2f}\\n\\n\")\n",
    "        f.write(f\"Summary:\\n\")\n",
    "        for key, value in summary.items():\n",
    "            f.write(f\"  {key}: {value}\\n\")\n",
    "        f.write(f\"\\nRecommendations:\\n\")\n",
    "        for rec in budget_analysis['recommendations']:\n",
    "            f.write(f\"  - {rec}\\n\")\n",
    "    \n",
    "    print(f\"\\nüíæ Analysis saved to: {analysis_file}\")\n",
    "    \n",
    "else:\n",
    "    print(\"‚ö†Ô∏è  No data available for budget analysis.\")\n",
    "    print(\"üì§ Please upload and process your CSV/PDF financial data first.\")\n",
    "    print(\"üí° The system works as a RAG model - it analyzes only your uploaded data.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
